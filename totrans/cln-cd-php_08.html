<html><head></head><body>
		<div id="_idContainer033">
			<h1 id="_idParaDest-100" class="chapter-number"><a id="_idTextAnchor100"/>8</h1>
			<h1 id="_idParaDest-101"><a id="_idTextAnchor101"/>Code Quality Metrics</h1>
			<p>Wouldn’t it be great if we could measure the quality of our software? Software developers often want to improve their software again and again – but maybe it is already “good enough.” How do we know when it reaches a good state?</p>
			<p>Software quality metrics were introduced by smart people in the early days of programming. In the 1970s, they thought about this topic and produced the ideas that are still in use today. Of course, we want to benefit from this knowledge and apply it to our own projects.</p>
			<p>In this chapter, we are going to cover the following topics:</p>
			<ul>
				<li>Introducing code quality metrics</li>
				<li>Gathering metrics in PHP</li>
				<li>The pros and cons of using metrics</li>
			</ul>
			<h1 id="_idParaDest-102"><a id="_idTextAnchor102"/>Technical requirements</h1>
			<p>If you have gone through the previous chapter and tried out all the tools, you already have everything that you need for this chapter installed. If not, please make sure to do so before you run the upcoming examples.</p>
			<p>The code files for this chapter can be found here: <a href="https://github.com/PacktPublishing/Clean-Code-in-PHP">https://github.com/PacktPublishing/Clean-Code-in-PHP</a></p>
			<h1 id="_idParaDest-103"><a id="_idTextAnchor103"/>Introducing code quality metrics</h1>
			<p>In this section, you will learn about how<a id="_idIndexMarker267"/> to measure the quality of software in general. We will look at some of the most used metrics in the PHP world and explain what they can tell you about your code, how to gather them, and when they are useful or not.</p>
			<h2 id="_idParaDest-104"><a id="_idTextAnchor104"/>Aspects of software quality </h2>
			<p>Before we dive into the numbers, we need<a id="_idIndexMarker268"/> to clarify one important thing first: what does software quality actually mean? Surely, everybody has a certain understanding of quality, but it might be hard to put this in words. Luckily, there are already<a id="_idIndexMarker269"/> existing models, such as the <strong class="bold">FURPS</strong> model, which was developed at Hewlett-Packard back in the 1980s. The acronym stands for the following:</p>
			<ul>
				<li><strong class="bold">Functionality</strong>: Is the software capable of dealing with a wide variety of use cases? Has it been developed with security in mind? </li>
				<li><strong class="bold">Usability</strong>: How good is the user experience? Is it documented and easy to understand?</li>
				<li><strong class="bold">Reliability</strong>: Is the software available at all times? How probable are crashes, or errors, that might affect the output?</li>
				<li><strong class="bold">Performance</strong>: Indicates the speed<a id="_idIndexMarker270"/> of the software. Does it make efficient use of the available resources? Does it scale well?</li>
				<li><strong class="bold">Supportability</strong>: Can the software be tested and maintained well? Is it easy to install and can it be translated (localized) into other languages?</li>
			</ul>
			<p>Further quality aspects include, among others, accessibility and legal conformity. As you can see, this model covers more aspects such as user experience and documentation than we as PHP developers will typically work on. That is why we can look at software quality from two different viewpoints: external and internal quality. Let us have a closer look at what that means:</p>
			<ul>
				<li><strong class="bold">External quality</strong>: Outward, or user-facing, aspects<a id="_idIndexMarker271"/> are part of the external quality of software. This covers a lot of the aspects we introduced previously. What they have in common is that they can be measured without touching or analyzing the code itself – think of performance testing tools that measure the response time of a request or end-to-end tests that emulate a user by automatically executing tests on the application.</li>
				<li><strong class="bold">Internal quality</strong>: As software developers, we usually<a id="_idIndexMarker272"/> care more about the internal quality of software. Is the code easy to read and understand? Can you extend it easily? Can we write tests for it? While users will never see the code, or are not concerned about its testability, it does affect them indirectly: code of high quality contains lesser bugs and is also often (but not always) faster and more efficient. It is also known to be easier to extend and maintain. Typically, these aspects<a id="_idIndexMarker273"/> can be checked using automated unit tests or code analyzers. </li>
			</ul>
			<p>In this book, we focus<a id="_idIndexMarker274"/> on the internal code quality. That is why we speak about code quality in particular and don’t use the broader term, software quality.</p>
			<h2 id="_idParaDest-105"><a id="_idTextAnchor105"/>Code quality metrics</h2>
			<p>Now that we have a better<a id="_idIndexMarker275"/> understanding of what code quality means, let us now have a look at what code quality metrics we want to talk about in this section:</p>
			<ul>
				<li>Lines of code</li>
				<li>The cyclomatic complexity</li>
				<li>The NPath complexity</li>
				<li>Halstead metrics</li>
				<li>The Change Risk Anti-Patterns index</li>
				<li>The maintainability index</li>
			</ul>
			<h3>The lines of code</h3>
			<p>Counting the <strong class="bold">Lines of Code</strong> (<strong class="bold">LOC</strong>) in a project is not a quality<a id="_idIndexMarker276"/> metric. However, it is a useful tool<a id="_idIndexMarker277"/> to grasp the size of a project – for example, when you start working on it. Furthermore, as we will see, it is used by other metrics as a base for their calculations. It is also helpful to have an idea about how many lines of code you are dealing with – for example, when you need to estimate refactoring efforts for certain classes. </p>
			<p>That is why we want to have a closer look at it now. First, we can differentiate the LOC further:</p>
			<ul>
				<li><strong class="bold">LOC</strong>: LOC simply <a id="_idIndexMarker278"/>counts all lines of code, including comments and blank lines.</li>
				<li><strong class="bold">Comment Lines of Code</strong> (<strong class="bold">CLOC</strong>): This metric tells you how many lines<a id="_idIndexMarker279"/> of your code are comments. It can be an indicator of how well the source code is commented on. However, as we know, comments tend to rot (i.e., they get outdated quickly and are often more harmful than they are useful), so there is no percentage or any other rule of thumb we can recommend. Still, it is interesting to know.</li>
				<li><strong class="bold">Non-Comment Lines of Code</strong> (<strong class="bold">NCLOC</strong>): If you want to compare the size of one project<a id="_idIndexMarker280"/> with another, leaving out the comments will give you a better picture of how much real code you need to deal with.</li>
				<li><strong class="bold">Logical Lines of Code</strong> (<strong class="bold">LLOC</strong>): For this metric, it is assumed that every<a id="_idIndexMarker281"/> statement equals one line of code. The following code snippet illustrates how it is supposed to work. Consider the following line of code:<p class="source-code">while($i &lt; 5) { echo “test”; /* Increment by one */</p><p class="source-code">  $i++; }</p></li>
			</ul>
			<p>Here, the LOC would be 1. Since we have three executable statements in this line, LLOC would count this as 3, as the code can also be written with each statement in one line:</p>
			<p class="source-code"><strong class="bold">while($i &lt; 5) {</strong></p>
			<p class="source-code">    <strong class="bold">echo “test”;</strong> </p>
			<p class="source-code">    /* Increment by one */</p>
			<p class="source-code">    <strong class="bold">$i++;</strong> </p>
			<p class="source-code">}</p>
			<p>In the preceding example, we highlighted<a id="_idIndexMarker282"/> the executable statements. Comments, empty<a id="_idIndexMarker283"/> lines, and syntactical elements such as brackets are not executable statements – that is why the full-line comment and the closing brace at the end of the loop are not counted as a logical line.</p>
			<h3>The cyclomatic complexity</h3>
			<p>Instead of just counting<a id="_idIndexMarker284"/> the lines of code, we can also measure<a id="_idIndexMarker285"/> the complexity of the code – for example, by counting the number of execution paths within a function. A common metric for this is the <strong class="bold">Cyclomatic Complexity</strong> (<strong class="bold">CC</strong>). It was introduced in the late 1970s but is nevertheless still useful. The idea behind the cryptic name is simple: we count the number of decision points, which are <strong class="source-inline">if</strong>, <strong class="source-inline">while</strong>, <strong class="source-inline">for</strong>, and <strong class="source-inline">case</strong> statements. Additionally, the function entry counts as one statement as well. </p>
			<p>The following example illustrates how the metric works:</p>
			<pre class="source-code">
// first decision point
function <strong class="bold">someExample($a, $b)</strong>
{
    // second decision point
    <strong class="bold">if ($a &lt; $b) {</strong>
        echo "1"; 
    } else {
        echo "2";
    }
    // third decision point
    <strong class="bold">if ($a &gt; $b) {</strong>
        echo "3";
    } else {
        echo "4";
    }
}</pre>
			<p>The CC for the preceding code snippet would be 3: the function entry counts as the first decision path and both <strong class="source-inline">if</strong> statements count as one decision path each as well. However, both <strong class="source-inline">else</strong> statements are not taken into account by definition, as they are part of the <strong class="source-inline">if</strong> clauses. This metric<a id="_idIndexMarker286"/> is especially useful to quickly assess the complexity<a id="_idIndexMarker287"/> of code that you do not know yet. It is often used to check a single function, but can also be applied to classes or even a whole application. If you have a function with a high CC, consider splitting it into several smaller functions to reduce the value.</p>
			<h3>The NPath complexity</h3>
			<p>A second<a id="_idIndexMarker288"/> metric of code<a id="_idIndexMarker289"/> complexity is the <strong class="bold">NPath complexity</strong>. The basic idea is similar to the CC, as it counts the decision paths of a function too. However, it counts <em class="italic">all</em> possible decision paths and not just the four statements (<strong class="source-inline">if</strong>, <strong class="source-inline">while</strong>, <strong class="source-inline">for</strong>, and <strong class="source-inline">case</strong>) that are defined for the CC. Furthermore, the function entry point is not counted as a decision path for this metric.</p>
			<p>Looking at the above example, the NPath complexity would be 4, because we have 2 * 2 possible paths through the function: both <strong class="source-inline">if</strong> statements, as well as both <strong class="source-inline">else</strong> statements. So, all four <strong class="source-inline">echo</strong> statements are considered decision paths. As mentioned previously, the function call itself is not considered. Now, if we added another <strong class="source-inline">if</strong> statement, the NPath complexity would increase to 8. This is because we would then have 2 * 2 * 2 possible paths. In other words, the metric grows exponentially, so it can rapidly become quite high. </p>
			<p>The NPath complexity depicts the actual effort to test a function better than the CC, as it tells us directly how many possible outcomes of the function we would need to test to achieve 100% test coverage. </p>
			<h3>Halstead metrics</h3>
			<p>Maurice Halstead<a id="_idIndexMarker290"/> introduced a set of eight metrics<a id="_idIndexMarker291"/> in the late 1970s, which are still in use today and are known as the <strong class="bold">Halstead metrics</strong>. They are based solely on the distinct and total number of operators (e.g., <strong class="source-inline">==</strong>, <strong class="source-inline">!=</strong>, and <strong class="source-inline">&amp;&amp;</strong>) and operands (e.g., function names, variables, and constants), but as you will see, they already tell you a lot about the inspected code.</p>
			<p>We do not need to know exactly how these<a id="_idIndexMarker292"/> metrics work. If you are interested, you can find out more about these metrics here: https://www.verifysoft.com/en_halstead_metrics.html. However, you should have an idea of what Halstead metrics there are:</p>
			<ul>
				<li><em class="italic">Length</em>: Calculating the sum of the total number of operators and operands tells us how much code we must deal</li>
				<li><em class="italic">Vocabulary</em>: The sum of the number of unique operators and operands already indicates the complexity of the code</li>
				<li><em class="italic">Volume</em>: Describes the information content of the code based on the length and vocabulary</li>
				<li><em class="italic">Difficulty</em>: Indicates the error proneness (i.e., how likely it is to introduce bugs) </li>
				<li><em class="italic">Level</em>: Inverts the difficulty – as in, the higher the level, the less error-prone it is</li>
				<li><em class="italic">Effort</em>: The effort that is necessary to understand the code</li>
				<li><em class="italic">Time</em>: Tells us how long it roughly took to implement it</li>
				<li><em class="italic">Bugs</em>: Estimates the number of bugs that the code contains</li>
			</ul>
			<p>These values will give you a rough<a id="_idIndexMarker293"/> indication of what type of code you are dealing<a id="_idIndexMarker294"/> with. Is it easy to understand? How much time was spent developing it? How many bugs can be expected? However, without comparing these values with results from other applications, they will not help you that much.</p>
			<h3>The Change Risk Anti-Patterns index</h3>
			<p>Another<a id="_idIndexMarker295"/> especially useful metric is the <strong class="bold">Change Risk Anti-Patterns</strong> (<strong class="bold">CRAP</strong>) index. It uses the CC<a id="_idIndexMarker296"/> and the code coverage of the code under consideration.</p>
			<p class="callout-heading">Code coverage</p>
			<p class="callout">You have probably heard the term code coverage<a id="_idIndexMarker297"/> a lot already. It is a metric that is used in context with automated tests and describes the number of lines of code (stated in percent of the total number of lines) that unit tests have been written for. We will discuss this metric and its prerequisites again later in the book when we are dealing with this topic in more detail.</p>
			<p>The combination of these two metrics is quite useful. Code that is not overly complex and has high test<a id="_idIndexMarker298"/> coverage is far more likely<a id="_idIndexMarker299"/> to be bug-free and maintainable than code that is complex and where there are not many tests for it.</p>
			<h3>The maintainability index</h3>
			<p>As the last metric<a id="_idIndexMarker300"/> in this section, we will look at the <strong class="bold">maintainability index</strong>. It will provide you with just one value<a id="_idIndexMarker301"/> that indicates the maintainability of the inspected code, or, in other words, it tells you how easy it will be to change it without introducing new bugs. Two things make this metric particularly interesting for us.</p>
			<p>Firstly, it is based on the aforementioned metrics and uses the LOC, Halstead metrics, and the CC to calculate the index. Yet again, we do not really need to know the exact formula. If you<a id="_idIndexMarker302"/> are interested, you can look it up here:<a href="https://www.verifysoft.com/en_maintainability.html"> https://www.verifysoft.com/en_maintainability.html</a>.</p>
			<p>Secondly, this metric will return a value that you can use to assess the code quality directly:</p>
			<ul>
				<li>85 and more: Good maintainability</li>
				<li>65 to 85: Moderate maintainability</li>
				<li>65 and below: Bad maintainability</li>
			</ul>
			<p>With this metric, you need no other code to compare it to. That is why it is particularly useful to quickly assess the code quality.</p>
			<p>In this section, we have gone through a lot of theory. Excellent job so far – you will not regret learning about it for sure because, in the next section, we will show you how to gather these metrics using even more PHP tools.</p>
			<h1 id="_idParaDest-106"><a id="_idTextAnchor106"/>Gathering metrics in PHP</h1>
			<p>In this section, we want<a id="_idIndexMarker303"/> to have a look at the tools there are in the PHP<a id="_idIndexMarker304"/> world to gather code quality metrics. As you will see shortly, these metrics are not just numbers – they will allow you to make educated guesses about how much effort it will take to refactor code. They will also help you to identify the parts of the code that will require the most attention.</p>
			<p>Again, we have curated a selection of tools for you:</p>
			<ul>
				<li><strong class="source-inline">phploc</strong></li>
				<li>PHP Depend</li>
				<li>PhpMetrics</li>
			</ul>
			<h2 id="_idParaDest-107"><a id="_idTextAnchor107"/>phploc</h2>
			<p>As we learned<a id="_idIndexMarker305"/> in the previous section, the abbreviation LOC stands for lines of code, so the name already reveals the main purpose of this tool. Being a basic metric, it already tells us quite a few things about a code base. <strong class="source-inline">phploc</strong> also provides further metrics, such as the CC, so it is worth having a closer look at it.</p>
			<h3>Installation and usage</h3>
			<p>The author <a id="_idIndexMarker306"/>of this tool, Sebastian<a id="_idIndexMarker307"/> Bergmann, is well known for <strong class="source-inline">phpunit</strong>, the de facto standard for automated tests in the PHP world. He recommends not installing it using Composer but using <strong class="source-inline">phar</strong> directly. We will discuss the pros and cons of this approach in the next chapter. For now, let us just follow the author’s advice and download <strong class="source-inline">phar</strong> directly:</p>
			<p class="source-code">$ wget https://phar.phpunit.de/phploc.phar</p>
			<p>This will download the latest version of <strong class="source-inline">phploc</strong> into the current directory. After downloading it, we can directly use it to scan a project:</p>
			<p class="source-code">$ php phploc.phar src</p>
			<p class="callout-heading">Scanning single files</p>
			<p class="callout">Although <strong class="source-inline">phploc</strong> is meant to be used <a id="_idIndexMarker308"/>on whole projects, it is also possible to specify a single file to scan. While the average measures make no sense because they are meant to be used on a whole project, it is still useful if you need to find out the LOC metrics or the CC for a class.</p>
			<p>The preceding command<a id="_idIndexMarker309"/> will scan the <strong class="source-inline">src</strong> folder with all its subfolders and gather information<a id="_idIndexMarker310"/> about it, which will be presented directly on the command line as shown in <em class="italic">Figure 8.1</em>:</p>
			<div>
				<div id="_idContainer027" class="IMG---Figure">
					<img src="image/Figure_8.01_B19050.jpg" alt="Figure 8.1: An example output of phploc (an excerpt)&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.1: An example output of phploc (an excerpt)</p>
			<p>That is quite a lot more information than just the LOC. The information is divided into the following categories:</p>
			<ul>
				<li><strong class="bold">Size</strong>: Obviously, the main reason<a id="_idIndexMarker311"/> for this tool to exist is to measure the size of a project by counting the number of lines of code, using the several ways of counting we introduced in the previous section. The focus lies on LLOC and you will get the <a id="_idIndexMarker312"/>averages for this metric per class, class method, and function.</li>
				<li><strong class="bold">CC</strong>: <strong class="source-inline">phploc</strong> will calculate the average CC values<a id="_idIndexMarker313"/> per LLOC, classes, and methods.</li>
				<li><strong class="bold">Dependencies</strong>: This section tells you how many<a id="_idIndexMarker314"/> accesses to the global state have been made and how many attributes and methods are being accessed statically. Both global and static access are considered as practices and should be avoided, so these numbers give you greater hints about the code quality.</li>
				<li><strong class="bold">Structure</strong>: In the last output <a id="_idIndexMarker315"/>section (which did not fit in the preceding screenshot), <strong class="source-inline">phploc</strong> returns more details on the code structure. There are no clear rules on how to interpret them; however, you can draw some conclusions from them. For example, see the following:<ul><li>Regarding the overall code size, how many namespaces are used? A large code base with only a few namespaces indicates that the project is not well structured.</li><li>Are interfaces used and how many compared to the project size? The usage of interfaces increases the interchangeability of classes and indicates well-structured code.</li></ul></li>
			</ul>
			<p>This is all we need to know about the functionality of <strong class="source-inline">phploc</strong> for now. It is a simple-to-use yet helpful tool that helps you get a grasp on the overall code quality and structure of a project quickly and should therefore be part of your toolkit. It does not tell you how to interpret the numbers, though, which requires some experience.</p>
			<h2 id="_idParaDest-108"><a id="_idTextAnchor108"/>PHP Depend</h2>
			<p>If there was a prize for the most metrics<a id="_idIndexMarker316"/> combined in one tool, then it would surely go to <strong class="bold">PHP Depend</strong> (<strong class="bold">PDepend</strong>). It covers all the metrics we discussed in the previous section, plus many more. However, it is not the most user-friendly tool there is. Plus, the website<a id="_idIndexMarker317"/> and the repository documentation are not perfect. Nevertheless, you should check it out.</p>
			<h3>Installation and usage</h3>
			<p>As before, this tool<a id="_idIndexMarker318"/> can be installed using Composer or downloading <strong class="source-inline">phar</strong> directly. We will go<a id="_idIndexMarker319"/> with the Composer-based installation for now:</p>
			<p class="source-code">$ composer require pdepend/pdepend --dev</p>
			<p>If there were no unpleasant surprises, you can execute it directly:</p>
			<p class="source-code">$ vendor/bin/pdepend <strong class="bold">--summary-xml=pdepend_summary.xml</strong> src</p>
			<p>Here, we already can see that the ancestor of PDepend is JDepend, a Java code quality tool, as the output is written into an XML file. The filename is specified using the <strong class="source-inline">--summary-xml</strong> option. Furthermore, we must specify the to-be-scanned folder as an argument.</p>
			<p><strong class="source-inline">PDepend</strong> does output some numbers, though, as can be seen in the following example output:</p>
			<pre class="source-code">
PDepend 2.10.3
Parsing source files:
...............................................          47
Calculating Cyclomatic Complexity metrics:
.................                                        355
Calculating Node Loc metrics:
.............                                            279
Calculating NPath Complexity metrics:
.................                                        355
Calculating Inheritance metrics:
.....                                                    101</pre>
			<p>We skipped some lines here. The numbers<a id="_idIndexMarker320"/> will only tell you how often each metric has been<a id="_idIndexMarker321"/> calculated for the given folder, so the direct output is not particularly helpful. To see the actual metrics, we need to open the XML report. In our case, the file that has been generated is called <strong class="source-inline">pdepend_summary.xml</strong>.</p>
			<p>The XML report is too huge to print in this book, so you best try it out yourself to see it in all its glory. However, we can show you how it is structured:</p>
			<pre class="source-code">
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;metrics&gt;
  &lt;files&gt;
    &lt;file name="/path/to/Namespace/Classname.php"/&gt;
    &lt;!-- ... --&gt;
  &lt;/files&gt;
  &lt;package name="Namespace"&gt;
    &lt;class name="Classname" fqname="Namespace\Classname"&gt;
      &lt;file name="/path/to/Namespace/Classname.php"/&gt;
      &lt;method name="methodName"/&gt;
      &lt;!-- ... --&gt;
    &lt;/class&gt;
    &lt;!-- ... --&gt;
  &lt;/package&gt;
&lt;/metrics&gt;</pre>
			<p>The <strong class="source-inline">&lt;metrics&gt;</strong> node represents the directory that was scanned in its entirety. It has the following child nodes:</p>
			<ul>
				<li><strong class="source-inline">&lt;files&gt;</strong>, which lists all the scanned files using the <strong class="source-inline">&lt;file&gt;</strong> child nodes.</li>
				<li><strong class="source-inline">&lt;package&gt;</strong>, which lists all the namespaces. Within this node, there are further <strong class="source-inline">&lt;class&gt;</strong> child nodes. For each class, there is a list of <strong class="source-inline">&lt;method&gt;</strong> nodes, one for each method in the class. Finally, the filename of the class is mentioned in another <strong class="source-inline">&lt;file&gt;</strong> node.</li>
			</ul>
			<p>Of course, this is not<a id="_idIndexMarker322"/> everything that <em class="italic">PDepend</em> will generate as output. For each<a id="_idIndexMarker323"/> node, it will add up dozens of attributes, which contain the names and values of the calculated metrics. This is an example node from a XML report that was generated on the source code of <em class="italic">PDepend</em> itself: </p>
			<pre class="source-code">
&lt;method name="setConfigurationFile" start="80" end="89"
  ccn="2" ccn2="2" loc="10" cloc="0" eloc="8" lloc="3"
  ncloc="10" npath="2" hnt="15" hnd="21"
  hv="65.884761341681" hd="7.3125" hl="0.13675213675214"
  he="481.78231731105" ht="26.765684295058"
  hb="0.020485472371812" hi="9.0098818928795"
  mi="67.295865328327"/&gt;</pre>
			<p>You should be able to recognize some metrics such as <strong class="source-inline">lloc</strong> (LOC) or <strong class="source-inline">ccn</strong> (CC Number) already. For the others, you will find explanations, or at least the long names, for the abbreviations in the <em class="italic">XML</em> report<a id="_idIndexMarker324"/> in the online documentation: <a href="https://pdepend.org/documentation/software-metrics/index.html">https://pdepend.org/documentation/software-metrics/index.html</a>.</p>
			<h3>Further options</h3>
			<p><em class="italic">PDepend</em> has two options<a id="_idIndexMarker325"/> you should know about:</p>
			<ul>
				<li><strong class="source-inline">--exclude</strong>: This will exclude a namespace (or package, in this terminology) from the scans. You can use multiple namespaces, separated by commas. Make sure to add quotes around the namespace(s):</li>
			</ul>
			<p><strong class="source-inline">$ vendor/bin/pdepend --summary-xml=pdepend_summary.xml </strong><strong class="bold">--exclude=”Your\Namespace,Another\Namespace”</strong><strong class="source-inline"> src</strong></p>
			<ul>
				<li><strong class="source-inline">--ignore</strong>: Allows you to ignore one or more folders. Again, don’t forget the quotes:</li>
			</ul>
			<p><strong class="source-inline">$ vendor/bin/pdepend --summary-xml=pdepend_summary.xml </strong><strong class="bold">--ignore=”path/to/folder,path/to/other/folder”</strong><strong class="source-inline"> src</strong></p>
			<p>It can also generate images in SVG format with further information. We will not cover them in this book, though, as there is a better tool for this, which you will find in the next section.</p>
			<p><em class="italic">PDepend</em> is powerful, but at the same<a id="_idIndexMarker326"/> time difficult to oversee. The generated output is hard to read and, once the project has become a bit bigger, becomes unusable unless you use other tools to parse the XML file. However, you may need the advanced metrics it provides one day, or you may work on a project where it is already in use. So, at least you are prepared now. </p>
			<h2 id="_idParaDest-109"><a id="_idTextAnchor109"/>PhpMetrics</h2>
			<p>Up until now, the world<a id="_idIndexMarker327"/> of PHP quality metrics was text-based only. This will change now, as we will now have a look at <em class="italic">PhpMetrics</em>, which will generate reports that are much better suited for the human eye and are even interactive.</p>
			<h3>Installation and usage</h3>
			<p>Let us<a id="_idIndexMarker328"/> add <em class="italic">PhpMetrics</em> to your project<a id="_idIndexMarker329"/> using Composer:</p>
			<pre class="source-code">
$ composer require phpmetrics/phpmetrics --dev</pre>
			<p>After all the files have been downloaded, you can immediately start generating your first report:</p>
			<pre class="source-code">
$ vendor/bin/phpmetrics --report-html=phpmetrics_report src</pre>
			<p>The <strong class="source-inline">--report-html</strong> option specifies<a id="_idIndexMarker330"/> the folder in which the report will be created. You can specify<a id="_idIndexMarker331"/> more than one folder to be scanned by providing them as a comma-separated list. For our example, however, we will just use the <strong class="source-inline">src</strong> folder. </p>
			<p>As a result, <em class="italic">PhpMetrics</em> will list several statistics that will already tell you a bit about the code. <em class="italic">Figure 8.2</em> shows an excerpt of the output, which might remind you of the output generated by <strong class="source-inline">phploc</strong>:</p>
			<div>
				<div id="_idContainer028" class="IMG---Figure">
					<img src="image/Figure_8.02_B19050.jpg" alt="Figure 8.2: The PhpMetrics console output (an excerpt)&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.2: The PhpMetrics console output (an excerpt)</p>
			<p>To open the actual HTML report<a id="_idIndexMarker332"/> that has just been generated, simply open the <strong class="source-inline">index.html</strong> file in that folder<a id="_idIndexMarker333"/> in your browser. Before we have a closer look at the generated report, let us see which other<a id="_idIndexMarker334"/> useful options <em class="italic">PhpMetrics</em> offers first:</p>
			<ul>
				<li><strong class="source-inline">--metrics</strong>: This option will return a list of the available metrics. It helps decipher abbreviations such as <strong class="source-inline">mIwoC</strong>.</li>
				<li><strong class="source-inline">--exclude</strong>: With this option, you can specify one or more directories to be excluded from scanning.</li>
				<li><strong class="source-inline">--report-[csv|json|summary-json|violations]</strong>: Allows you to save the results in different<a id="_idIndexMarker335"/> report formats other than HTML – for example, <strong class="source-inline">--report-json</strong>.</li>
			</ul>
			<p class="callout-heading">Opening the browser from the command line</p>
			<p class="callout">If you are using a Linux-based operating system, such as Ubuntu, you can quickly open an HTML file from the command line as follows:</p>
			<p class="callout"><strong class="source-inline">$ firefox phpmetrics_report/index.html</strong></p>
			<p class="callout">Alternatively, see the following:</p>
			<p class="callout"><strong class="source-inline">$ chromium phpmetrics_report/index.html</strong></p>
			<h3>Understanding the report</h3>
			<p>If you have opened a <em class="italic">PhpMetrics</em> report for the first time, you will find<a id="_idIndexMarker336"/> a wide variety of information. We will not dive into every little detail but will show you which parts of the report we think are the most valuable to start with. </p>
			<p>To illustrate the usage of <em class="italic">PhpMetrics</em> better, we randomly chose an existing open source package called <strong class="source-inline">thephpleague/container</strong> as a code base to work on. It is an excellent PSR-11-compliant dependency injection container, which is just the right size to use as an example. <em class="italic">Figure 8.3</em> shows the overview page of an example report that we generated for it: </p>
			<div>
				<div id="_idContainer029" class="IMG---Figure">
					<img src="image/Figure_8.03_B19050.jpg" alt="Figure 8.3: A PhpMetrics report overview&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.3: A PhpMetrics report overview</p>
			<h4>Key metrics</h4>
			<p>On the left-hand side, you will find<a id="_idIndexMarker337"/> the menu where you can access other pages of the report. The top part of the page is populated with a couple of key metrics, where the most interesting ones are:</p>
			<ul>
				<li><strong class="bold">Lines of code</strong> tells you more about the size of this project. By clicking on the label, you will be sent to another page with a detailed list of all the classes and their related size metrics such as LOC.</li>
				<li><strong class="bold">Violations</strong> shows you the number of violations that <em class="italic">PhpMetrics</em> has discovered. Again, by clicking on the label, you will be sent to another page with a list of classes and their violations – for example, if they are too complex (<em class="italic">Too complex method code</em>), have a high bug probability (<em class="italic">Probably bugged</em>), or use too many other classes or other dependencies (<em class="italic">Too dependent</em>).</li>
				<li><strong class="bold">Average cyclomatic complexity by class</strong> tells you exactly what it says on the tin. The detailed view gives you more information about the complexity on a class level.</li>
			</ul>
			<p>The other boxes offer <a id="_idIndexMarker338"/>interesting information as well, but the preceding ones are already perfect for getting a quick view of the most problematic parts of the code.</p>
			<h4>Maintainability or complexity</h4>
			<p>Underneath the key<a id="_idIndexMarker339"/> metrics, <em class="italic">PhpMetrics</em> shows a diagram, among other things, which you surely already spotted when first opening the report: the <strong class="bold">Maintainability / complexity</strong> graph. It consists of a colored circle for each namespace of the project, where the size of the circle represents the CC of a class. The bigger the circle, the higher the complexity. The color shows you the maintainability index, ranging from green (high) to red (low).</p>
			<p>If you hover your mouse over a circle, you can see the namespace the circle represents and the two metrics in detail:</p>
			<div>
				<div id="_idContainer030" class="IMG---Figure">
					<img src="image/Figure_8.04_B19050.jpg" alt="Figure 8.4: The Maintainability / complexity graph with a popup&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.4: The Maintainability / complexity graph with a popup</p>
			<p>This graph is extremely<a id="_idIndexMarker340"/> useful for quickly grasping the overall code quality – the fewer big red circles there are, the better. This way, you can see the problematic parts of your code easily.</p>
			<h4>Object relations</h4>
			<p>When you select <strong class="bold">Object relations</strong> from the left-hand menu, a graph<a id="_idIndexMarker341"/> that shows the relations between each namespace will appear. Hovering the mouse pointer over a text label will highlight its relations. The graph becomes massive, so we can not show it to you in this book in its full beauty, but we can at least give a first impression:</p>
			<div>
				<div id="_idContainer031" class="IMG---Figure">
					<img src="image/Figure_8.05_B19050.jpg" alt="Figure 8.5: An Object relations graph&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.5: An Object relations graph</p>
			<h4>Coupling</h4>
			<p>The coupling of classes<a id="_idIndexMarker342"/> states how they depend on each other. There are two main metrics:</p>
			<ul>
				<li><strong class="bold">Afferent couplings</strong> (<strong class="bold">Ca</strong>) tell you the number of classes<a id="_idIndexMarker343"/> that depend on this class. Too many dependencies indicate the importance of a class for the project.</li>
				<li><strong class="bold">Efferent couplings</strong> (<strong class="bold">Ce</strong>) give you an idea of how many<a id="_idIndexMarker344"/> dependencies a class uses. The higher this is, the more the class depends on others.</li>
			</ul>
			<h4>Package-oriented metrics</h4>
			<p>The last graph<a id="_idIndexMarker345"/> we want to show you is the <strong class="bold">Abstractness vs. Instability</strong> graph. As the name already indicates, it shows the relationship between<a id="_idIndexMarker346"/> abstractness and the instability of packages. It was introduced by Robert Martin and is based on his work on object-oriented metrics. <em class="italic">Figure 8.6</em> shows you an example:</p>
			<div>
				<div id="_idContainer032" class="IMG---Figure">
					<img src="image/Figure_8.06_B19050.jpg" alt="Figure 8.6: An Abstractness vs. Instability graph&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.6: An Abstractness vs. Instability graph</p>
			<p>But what exactly do these two terms mean in the context of software development? Let us look at the following definitions:</p>
			<ul>
				<li><strong class="bold">Abstractness</strong> (<strong class="bold">A</strong>) is the ratio of abstract base classes and interfaces to the number of total classes in a namespace or package. The more these abstract types are included in the package, the easier and less risky the changes become. <em class="italic">A</em> ranges from <strong class="source-inline">0</strong> (concrete) to <strong class="source-inline">1</strong> (abstract).</li>
				<li><strong class="bold">Instability</strong> (<strong class="bold">I</strong>) tells you how vulnerable a package is to change, expressed through a ratio of the <em class="italic">Ce</em> to the total <em class="italic">Ce</em> and <em class="italic">Ca (Ce + Ca)</em>. In other words, the<a id="_idIndexMarker347"/> more dependencies it has, the less stable it will be. <em class="italic">I</em> ranges from <strong class="source-inline">0</strong> (stable) to <strong class="source-inline">1</strong> (unstable).</li>
			</ul>
			<p>Martin stated that packages that are stable and thus highly independent of other classes should also have a high level of <em class="italic">A</em>. Vice versa, unstable packages should consist of concrete classes. So, in theory, the <em class="italic">A</em> of a class weighs out its <em class="italic">I</em>. This means that ideally, <em class="italic">A</em> plus <em class="italic">I</em> should be <strong class="source-inline">1</strong> (<em class="italic">A + I = 1</em>). This equation also draws the angled line from the top-left to the bottom-right corner of the graph. You should strive to keep your packages close to the line. </p>
			<p>In the actual report, you will <a id="_idIndexMarker348"/>find a table below the graph where you will find the values in more detail. If you hover the mouse pointer over a circle, a popup will appear that tells you the name of the class the circle represents, as well as the <em class="italic">A</em> (the first digit) and the <em class="italic">I</em> (the second digit).</p>
			<h4>Other information</h4>
			<p>This ends our tour through <em class="italic">PhpMetrics</em>. There is a lot more<a id="_idIndexMarker349"/> to discover, such as, for example, the <em class="italic">ClassRank</em>, where the famous <em class="italic">PageRank</em> algorithm<a id="_idIndexMarker350"/> from Google is used to rank the classes according to their importance (i.e., the number of interactions they have with other code parts). We can’t cover everything in this book – however, by now, you already know many of the metrics. Its documentation is quite helpful to you. You will find a link to it on every page in the upper-right-hand corner.</p>
			<h1 id="_idParaDest-110"><a id="_idTextAnchor110"/>The pros and cons of using metrics</h1>
			<p>In the two previous chapters of this book, you have learned about many tools and metrics that exist solely to help you write better software. The knowledge and wisdom and countless hours of endeavor on the part of hundreds if not thousands of software engineers can be added to your project in a matter of minutes.</p>
			<p>The other side of the coin is that you might already feel completely overwhelmed by the sheer number of possibilities. Which tools should you choose? Which metrics should you focus on in the future? </p>
			<p>If you have that feeling already, do not worry. We will not leave you alone in all this mess but help you find a setup that fits your needs during the next chapters. To begin with, let us take the time to look at the pros but also cons of using code quality metrics.</p>
			<h2 id="_idParaDest-111"><a id="_idTextAnchor111"/>The pros</h2>
			<p>First, each software project<a id="_idIndexMarker351"/> is a unique piece of work. It grows based on certain circumstances, such as the skill sets of the developers and the available packages or frameworks at that time, but also external factors, such as deadlines, which often enough affect code quality negatively.</p>
			<p>Code metrics help you to get an overview of the current state that a project is in. If you, for example, take over a project made by a former team member, you want to know what awaits you. By having an idea of the code quality, you can immediately adjust your estimated efforts on future tickets in whatever direction.</p>
			<p>Code quality metrics also help you understand where code needs to be improved. It is excellent training to refactor your code, and by using the metrics, you know when you have succeeded. Regardless of whether you are working on your own pet project, you want to contribute to an open source project, or you work in a team, it is always a nice achievement to finally get some more green lights on the reports.</p>
			<p>If you found a piece of code that urgently needed refactoring for a valid reason, but your project manager did not want you to do it, you could use the metrics to show them how terrible things are and that it is just a judgement based your own opinion. Code metrics are unbiased and (painfully) honest.</p>
			<p>Finally, another important use case of these metrics is to prevent you from writing bad code in the first place. Sometimes, it might<a id="_idIndexMarker352"/> be a bit annoying to write code that adheres to all these rules but be assured that the effort pays off eventually. </p>
			<h2 id="_idParaDest-112"><a id="_idTextAnchor112"/>The cons</h2>
			<p>Previously, we said that deadlines<a id="_idIndexMarker353"/> can harm code quality because they keep us from refactoring code smells or adding more tests. While this is true, we must be aware that once they start by measuring the quality of their code, some developers start to refactor a lot more code than necessary because they get rewarded with better metrics. Why is that problematic?</p>
			<p>For example, imagine there is a class in your current project that has a low maintainability index, high NPath complexity, and just by looking at it, you can immediately see how bad it is. However, it has matured over time, being fixed so often that at some point, it has proven to work without bugs. Now, your tools tell you that this class is of bad quality. Should you still jump on it and start refactoring it?</p>
			<p>There is, of course, no clear yes or no. As mentioned previously, if you work on code in your spare time, it makes sense (and is fun, too) to refactor a class to remove most of the code smells. If you are working on commercial projects, as in, working as a software engineer for a living, you will not always have the time to do so. There are bugs to squeeze, which make the users of your software unhappy, while on the other hand there are features to implement, for which they are desperately waiting. Overall, it is the satisfied customers who pay your bill. Finding the sweet spot between development speed and code quality is never easy – you just need to be aware that you sometimes have to take the bitter pill and leave bad code alone for now.</p>
			<p>Do not use metrics to compete against colleagues, or worse, to talk badly about former developers who left you alone with the project. Be aware that everybody works as well as possible, based on their skills. Nobody deliberately tries to write bad code – often enough, it happens because the developers have never heard about clean coding principles or they were under such sheer time pressure that they had to do copy and paste coding to make their <a id="_idIndexMarker354"/>managers or customers happy. Your work environment should be a place of respect, helpfulness, and tolerance, not competition.</p>
			<h1 id="_idParaDest-113"><a id="_idTextAnchor113"/>Summary</h1>
			<p>This chapter introduced you to some of the most used code quality metrics in the PHP world. Furthermore, we presented you with the tools that help you gather them. Of course, there are many more that we could not cover in this book, but you do not have to know them all – you are now equipped with a solid understanding of code quality metrics that will help you in your daily working routine.</p>
			<p>Code quality tools and metrics are surely no silver bullet for all problems. On the one hand, they can be extremely helpful for improving your code. On the other hand, you should not take them as the ultimate measure. There are numerous examples of successful types of software that would never pass these quality checks, such as WordPress. Be sure, though, that the creators of WordPress would have done things differently if they had known beforehand.</p>
			<p>In the next chapter, we will leave the realm of theory. We will learn how to organize the tools that we introduced in the last two chapters into our projects. Every project is unique, so we will offer you different flavors to fit your needs.</p>
			<h1 id="_idParaDest-114"><a id="_idTextAnchor114"/>Further reading</h1>
			<ul>
				<li><strong class="bold">dePHPend</strong> (<a href="https://dephpend.com/">https://dephpend.com/</a>) is a tool that can draw UML diagrams for your PHP code and be used to spot problems in your architecture.</li>
			</ul>
		</div>
	</body></html>