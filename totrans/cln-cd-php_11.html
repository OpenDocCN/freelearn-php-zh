<html><head></head><body>
		<div id="_idContainer049">
			<h1 id="_idParaDest-144" class="chapter-number"><a id="_idTextAnchor145"/>11</h1>
			<h1 id="_idParaDest-145"><a id="_idTextAnchor146"/>Continuous Integration</h1>
			<p>You have learned the theory about writing clean <strong class="bold">PHP: Hypertext Preprocessor</strong> (<strong class="bold">PHP</strong>) code, and you now know the necessary tools and metrics that help us to achieve and keep to high quality levels. However, what is still missing is the integration of all these technologies into a workflow that facilitates your daily work.</p>
			<p>In the following pages, we will elaborate on <strong class="bold">continuous integration</strong> (<strong class="bold">CI</strong>) and learn by example how to set up a simple but effective automated workflow.</p>
			<p>Furthermore, we will show you how to set up a selection of code quality tools locally in a way that they support you the most, without having to manually run them. Additionally, we will tell you some best practices about how to add these workflows to an existing project.</p>
			<p>The main topics we will cover are listed here:</p>
			<ul>
				<li>Why you need CI</li>
				<li>The build pipeline</li>
				<li>Building a pipeline with GitHub Actions</li>
				<li>Your local pipeline—Git hooks</li>
				<li>Excursion—Adding CI to existing software</li>
				<li>An outlook on <strong class="bold">continuous delivery</strong> (<strong class="bold">CD</strong>)</li>
			</ul>
			<h1 id="_idParaDest-146"><a id="_idTextAnchor147"/>Technical requirements</h1>
			<p>Additional to the setup of the previous chapters, you will require a GitHub account to be able to follow all examples. This will come with no additional costs, though, as we are only using the free plan.</p>
			<p>The example application that we will use in this chapter can be downloaded from the GitHub repository to this book: <a href="https://github.com/PacktPublishing/Clean-Code-in-PHP/tree/main/ch11/example-application">https://github.com/PacktPublishing/Clean-Code-in-PHP/tree/main/ch11/example-application</a>.</p>
			<h1 id="_idParaDest-147"><a id="_idTextAnchor148"/>Why you need CI</h1>
			<p>Writing <a id="_idIndexMarker485"/>software is a time-consuming and thus costly process. If you develop software for fun, it will “only” cost you your leisure time. If you work for a company (be it as a contractor or full-time employee), the time is even more valuable, as you get paid for it. As a matter of fact, companies want to reduce costs, and thus they do not want to spend more money on a feature than necessary.</p>
			<p>A big part of our daily work is to fix defects. Delivering bug-free software is something that probably all developers would like to achieve. We do not make mistakes deliberately, yet they will always happen. There are ways, however, to reduce the costs of bugs.</p>
			<h2 id="_idParaDest-148"><a id="_idTextAnchor149"/>The costs of a bug</h2>
			<p>A bug<a id="_idIndexMarker486"/> is considerably costly because it adds no value to the product. Therefore, we aim to catch these bugs as early as possible—the earlier we catch them, the fewer costs they will cause. The following screenshot visualizes how the costs to fix a bug increase significantly the later it appears in the development process:</p>
			<div>
				<div id="_idContainer040" class="IMG---Figure">
					<img src="image/Figure_11.1_B19050.jpg" alt="Figure 11.1: Estimated relative costs of fixing a bug based on the time of its detection&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.1: Estimated relative costs of fixing a bug based on the time of its detection</p>
			<p>But what is the <a id="_idIndexMarker487"/>reason for the massive cost increase over time? And why do bugs even cost money?</p>
			<p>In the early stages, costs mainly arise from the required time to resolve the issue. If a bug could have been avoided just by better requirements, for example, then this requires less effort as it was discovered during the manual testing. If a bug was found in production, many people are involved in fixing it: first, a helpdesk employee needs to acknowledge the bug reported by a customer and pass it over to the <strong class="bold">quality assurance</strong> (<strong class="bold">QA</strong>) engineer, who <a id="_idIndexMarker488"/>reproduces it and writes a proper bug ticket.</p>
			<p>This ticket then gets assigned to the product manager, who, after taking time to reproduce and verify the defect as well, plans it in for the next sprint. The ticket eventually gets assigned to one developer, who will need some time to reproduce and fix it. But it is not over here because the bug fix probably requires a code review from another developer and gets double-checked from the product manager or QA engineer as well before it can finally be released.</p>
			<p>Once “escaped” from the developer’s local environment, all this overhead raises the costs of the defect significantly. Additionally, if the bug is already in production, it can lead to customers not wanting to use<a id="_idIndexMarker489"/> the product anymore because they are no longer happy with it. This is called <strong class="bold">customer churn</strong>.</p>
			<p>Even if you are not working on a commercial product, but—for example—on an open source project, the concept can <a id="_idIndexMarker490"/>be translated into time or effort. A bug will lead to an issue report that you first need to read and understand, probably asking some more questions, and waiting for the ticker author to reply. If your software is too buggy, people will use it less, and all your previous efforts might have been in vain at some point.</p>
			<h2 id="_idParaDest-149"><a id="_idTextAnchor150"/>How to prevent bugs</h2>
			<p>Fortunately, we now have a whole<a id="_idIndexMarker491"/> toolbox at your side that can help us find bugs in your code before somebody else does. We just have to use it—and this is already a problem because we developers are usually lazy people.</p>
			<p>Of course, you could run all the tools manually before every deploy. Let us say you want to deploy some code to production. After merging the code into the <strong class="source-inline">main</strong> branch, the following steps should be executed to ensure that no broken code gets delivered to production:</p>
			<ol>
				<li>Using the PHP linter to ensure the syntactical correctness of the code</li>
				<li>Executing a code style checker and fixer to keep the code styling aligned</li>
				<li>Finding potential issues using static code analysis</li>
				<li>Execution of all automated test suites to ensure your code still works</li>
				<li>Creating reports for the used code quality metrics</li>
				<li>Cleaning up the build folder and creating an archive of the code to deploy</li>
			</ol>
			<p>This is quite a list of things to keep in mind. Nobody would do this over a longer period without making mistakes at some point, so, naturally, you would start writing scripts that help you to execute these steps in one go. This is already a good improvement, and we will also make use of it a bit further on in this chapter.</p>
			<h2 id="_idParaDest-150"><a id="_idTextAnchor151"/>Introducing CI</h2>
			<p>Running all the <a id="_idIndexMarker492"/>steps from the previous section in your local environment will take some time, and during the checks run, you can hardly work on anything else, so you have to wait until they are finished. So, why not load this whole workflow onto another, dedicated server?</p>
			<p>This is precisely what CI does: it describes the automated process of putting all necessary components of your application together into <a id="_idIndexMarker493"/>a <strong class="bold">deliverable</strong> so that it can be deployed to the wanted environments. During the process, automated checks will ensure the overall quality of the code. It is important to keep in mind that if one of the checks fails, the whole build will be considered as failed.</p>
			<p>There are <a id="_idIndexMarker494"/>many <strong class="bold">CI tools</strong> available, such as Jenkins, which is usually self-hosted (that is, operated by you or someone in your team or company). Or, you can choose paid services such as GitHub Actions, GitLab CI, Bitbucket Pipelines, or CircleCI.</p>
			<p>You will often read the abbreviation <em class="italic">CI/CD</em>, and we will also use it throughout this book. <strong class="bold">CD</strong> stands for <strong class="bold">continuous delivery</strong>, a concept <a id="_idIndexMarker495"/>that we will cover at the end of this chapter. For now, you do not need to care about it, though.</p>
			<p>Setting up one of these tools sounds like a lot of work, but it also has some great benefits, such as the following:</p>
			<ul>
				<li><strong class="bold">Scalability</strong>: If you work in a <a id="_idIndexMarker496"/>team, using the local setup will quickly cause problems. Any changes to the build process would need to be done on the computer of every developer. Although the build script would be part of your repository, people may forget to pull the latest changes from it before deploying, or something else might go wrong.</li>
				<li><strong class="bold">Speed</strong>: Automated tests or static code analysis is a pretty resource-consuming job. Although today’s computers are powerful, they have to do a lot of concurring tasks, and you do not want to additionally run a build pipeline on your local system. <strong class="bold">CI/CD servers</strong> are doing <a id="_idIndexMarker497"/>only this one job, and they are usually doing it fast. And even if they are slow, they still take the load from your local system.</li>
				<li><strong class="bold">Non-blocking</strong>: You need a build environment to run all the tools and checks on your code. Using your local development environment for this will simply block it for the duration of the build, especially when you use slower test types such as integration or <strong class="bold">end-to-end</strong> (<strong class="bold">E2E</strong>) tests. Running two environments on your local system—one for development and one for CI/CD—is not recommended, as you will quickly end up in a configuration hell (just think of blocking a database of web server ports).</li>
				<li><strong class="bold">Monitoring</strong>: Using a dedicated CI/CD server will let you keep an overview of who deployed what and when. Imagine that your production system is suddenly broken—using a CI/CD server, you can immediately see what the last changes have been and deploy the previous version of your application with a few clicks. Furthermore, CI/CD tools keep you up to date and inform you—for example—via email or your favorite messenger application about any build and deploy activities.</li>
				<li><strong class="bold">Handling</strong>: A <a id="_idIndexMarker498"/>handwritten deployment script will surely do the work, but it takes a lot of time to make it as comfortable and flexible as a modern CI/CD solution. Plus, if you go with the business standards, it is much more likely that other developers of your team will already have experience with it.</li>
			</ul>
			<p>The preceding points hopefully give you an idea of how much you will benefit from using CI. An integral part of each CI/CD tool is the so-called build pipeline, which we will explain in detail in the next section.</p>
			<h1 id="_idParaDest-151"><a id="_idTextAnchor152"/>The build pipeline</h1>
			<p>In the previous section, we<a id="_idIndexMarker499"/> listed the many necessary steps to make our code ready to be shipped to production. In the context of CI, a combination of these steps is what we call the <strong class="bold">build pipeline</strong>: it takes the input (in our case, all the application code), runs it through several tools, and creates <a id="_idIndexMarker500"/>so-called <strong class="bold">build artifacts</strong> out of it. They are the outcome of a build—usually, this includes the <strong class="bold">deliverable</strong> (a package<a id="_idIndexMarker501"/> of the application code that is ready to be moved to the desired environment), plus additional data, such as build logs, reports, and so on.</p>
			<p>The following diagram gives you a schematic overview of what a typical build pipeline could look like. Since it is not <a id="_idIndexMarker502"/>executed in your local environment, it requires two additional steps: <em class="italic">creating a build environment</em> and <em class="italic">building an application</em>:</p>
			<div>
				<div id="_idContainer041" class="IMG---Figure">
					<img src="image/Figure_11.2_B19050.jpg" alt="Figure 11.2: Schema of a CI pipeline&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.2: Schema of a CI pipeline</p>
			<p class="callout-heading">Other languages in the pipeline</p>
			<p class="callout">In this book, we will only have a look at the PHP-related parts of the pipeline, yet a modern web application does not only consist of PHP. Especially for the frontend-facing code, there is another whole universe of tools that needs to be part of the pipeline, too. Yet in the end, the process is very similar.</p>
			<p>In the next sections, we will go into more detail about every build stage. We will keep it theoretical at first, and then give examples of technical implementation later in this chapter.</p>
			<h2 id="_idParaDest-152"><a id="_idTextAnchor153"/>Stage 1: Build project</h2>
			<p>The <a id="_idIndexMarker503"/>CI pipeline requires a dedicated build instance of our application, where we can run all tools and checks on it isolated. This can roughly be divided into two steps: creating a build environment and running the necessary build tools.</p>
			<h3>Creating a build environment</h3>
			<p>To build an <a id="_idIndexMarker504"/>application somewhere else than on the local development system, we first need to create<a id="_idIndexMarker505"/> a <strong class="bold">build environment</strong>. How exactly the environment is provided depends on the used CI/CD tool. This can either be a dedicated server that offers separated workspaces for every project, or a completely containerized Docker environment, which is spun up every time you require it and only lasts for the duration of the build.</p>
			<p>Once a build <a id="_idIndexMarker506"/>environment exists, we need to download all the source code there, but without external packages or other dependencies for now. Most likely, your code will be stored in a Git repository and either hosted on a private Git server, or a commercial service. Downloading a copy of a specific branch of a repository is <a id="_idIndexMarker507"/>called <strong class="bold">checkout</strong>.</p>
			<p>We have to pay attention to which branch of the repository the code gets checked out from. This depends<a id="_idIndexMarker508"/> on what you want to build. If you intend to check the code of a <strong class="bold">pull request</strong> (<strong class="bold">PR</strong>) (a set of changes to the code, which someone requests to be integrated into the code base), then you need to check out the branch of that feature. If you wish to upload the latest version of your application to production, you want to check out the <strong class="source-inline">main</strong> branch.</p>
			<p class="callout-heading">Main versus master branch</p>
			<p class="callout">Throughout the<a id="_idIndexMarker509"/> history of computers, the terms <em class="italic">master</em> and <em class="italic">slave</em> have been widely used, be it for <a id="_idIndexMarker510"/>hard disk configuration, database replication, or—of course—Git. However, these terms are harmful to many people, so the <strong class="bold">information technology</strong> (<strong class="bold">IT</strong>) people decided to finally change this into less offensive terms, such as <em class="italic">main</em> and <em class="italic">replica</em>. GitHub, for example, by default calls the <strong class="source-inline">main</strong> branch simply <em class="italic">main</em> instead of <em class="italic">master</em> nowadays. You will still find repositories out there that use the old branch name. In this book, though, we will stick with the new terminology.</p>
			<p>Do not worry, however, if your project is not hosted using Git—this step is still necessary because we need to get the code on the CI/CD server. Be it via Git, Mercurial, <strong class="bold">Subversion</strong> (<strong class="bold">SVN</strong>), or even<a id="_idIndexMarker511"/> direct file download, it does not matter in the end. The outcome of this step is to have the code we want to deploy readily available on the CI/CD server so that we can start installing the dependencies in the next step.</p>
			<h3>Building the application</h3>
			<p>Building the <a id="_idIndexMarker512"/>application is similar to installing it on a new system. In the previous step, we made sure that the source code is available in the environment. In this step, we need to execute any required build steps. This usually includes the following:</p>
			<ul>
				<li><strong class="bold">Installing external dependencies</strong>: Your repository should only contain your own code, with no external dependencies. These we manage, for example, via Composer<a id="_idIndexMarker513"/> or the <strong class="bold">PHAR Installation and Verification Environment</strong> (<strong class="bold">Phive</strong>).</li>
				<li><strong class="bold">Creating configuration files</strong>: Your repository should not contain any passwords or other confidential data such as <strong class="bold">application programming interface</strong> (<strong class="bold">API</strong>) keys. They can<a id="_idIndexMarker514"/> be securely stored in the CI/CD tool and used to create an environment file (<strong class="source-inline">.env</strong>, for example) during this stage.</li>
				<li><strong class="bold">Preparing the test database</strong>: To run integration or E2E tests, the build instance needs a working database. Commonly, this is done by creating a test database, importing the database schema, running any additional database migrations, and—finally—populating the <a id="_idIndexMarker515"/>database with test data.</li>
			</ul>
			<p>To reduce the build time, many modern CI/CD tools offer caching. If activated, they will keep the dependencies in temporary storage after the first download. It is generally a good idea to turn this on, if not activated by default.</p>
			<h2 id="_idParaDest-153"><a id="_idTextAnchor154"/>Stage 2 – Code analysis</h2>
			<p>We covered <a id="_idIndexMarker516"/>code quality tools in <a href="B19050_07.xhtml#_idTextAnchor084"><em class="italic">Chapter 7</em></a><em class="italic">, Code Quality Tools,</em> in detail. Now, it<a id="_idIndexMarker517"/> is time to add these tools to our pipeline to ensure that they will be executed for every change that gets introduced.</p>
			<h3>PHP linter</h3>
			<p>If you merge code into <a id="_idIndexMarker518"/>another branch, it can always happen that the code breaks. Git has very sophisticated merge algorithms, but still, it cannot do magic. Given that you have a test suite with high coverage, some tests will surely break if there were a syntax error that had been caused by the merge. So, why should we run this extra step? We recommend it because the PHP linter <a id="_idIndexMarker519"/>has two advantages: it runs very fast, and it will check all PHP files, no matter if there are tests for them or not.</p>
			<p>We want our<a id="_idIndexMarker520"/> pipeline to fail fast if any issues have been detected. Therefore, before you execute any long-running tasks, it makes sense to run a quick syntax check in the beginning. They would break in any case, and you would lose some valuable time. As a rule of thumb, the faster the check runs, the earlier it will appear in the pipeline.</p>
			<h3>Code style checker</h3>
			<p>After<a id="_idIndexMarker521"/> checking the code syntax, it is time to check the code <a id="_idIndexMarker522"/>style. This operation is fast too, so it makes sense to run it early in the pipeline. For our example, we will go with the <strong class="bold">PHP Coding Standards Fixer</strong> (<strong class="bold">PHP-CS-Fixer</strong>), which we <a id="_idIndexMarker523"/>already introduced in <a href="B19050_07.xhtml#_idTextAnchor084"><em class="italic">Chapter 7</em></a><em class="italic">, Code Quality Tools</em>.</p>
			<p>There is a subtle but important difference between running PHP-CS-Fixer locally and in the CI/CD pipeline: for the latter, we will only use it to check the code, but not to fix it. We do not want the pipeline to <em class="italic">change</em> our code, just to <em class="italic">analyze</em> it. In other words, our pipeline will only check if the code is correctly formatted (according to the rules we defined), but it will not attempt to fix it automatically; if any of the rules are violated, the build has failed.</p>
			<p>No rules are saying that the CI/CD pipeline should not change the code. However, it adds complexity to automatically commit the changes to the repository during the process. Moreover, it requires a very well-tested application, and you need to trust that the tool of your choice does not break anything. Usually, they work well, but do you want to risk it?</p>
			<p>In your local environment, it makes sense to run the fixer alongside the code style checker. We will discuss the local setup in one of the next sections of this chapter.</p>
			<h3>Static code analysis</h3>
			<p>At this <a id="_idIndexMarker524"/>point, we know that our code is syntactically<a id="_idIndexMarker525"/> correct and formatted according to our rules. Both previous checks are usually performed quickly, so our build would fail early if any of those easy-to-detect problems had occurred.</p>
			<p>Now, it is time to run the slower tasks. The static code analysis usually takes a bit longer than the two previous ones, but it is by far not as slow as running the automated tests. Essentially, this step is not that different from the linting and code style checking: if the rules we have defined earlier are violated, the build will fail.</p>
			<p>If you are introducing CI to an existing project, the challenge is to find the sweet spot in error reporting. On the one hand, you want to keep the developers happy and not force them to fix dozens of issues introduced by other developers on every file they touch. On the other hand, you need to set the threshold tight enough to enforce at least some refactoring with every code change.</p>
			<p>There is no<a id="_idIndexMarker526"/> golden rule here, unfortunately, and <a id="_idIndexMarker527"/>you need to experiment with the settings. At a later point, when most of the issues of the static code analysis reports are solved, you need to tighten the error reporting rules a little so that your project does not stagnate at a certain level.</p>
			<h2 id="_idParaDest-154"><a id="_idTextAnchor155"/>Stage 3 – Tests</h2>
			<p>Once our code<a id="_idIndexMarker528"/> has reached this point in the pipeline, we are convinced that it is syntactically correct, adheres to our code styling guidelines, and has no <a id="_idIndexMarker529"/>general flaws according to our static code analysis rules. So, we will now run the step in the pipeline, which usually takes the longest time: the automated tests.</p>
			<p>As we introduced in the previous chapter, there are more than just unit tests to consider. Often, a project such as a web service has at least some integration tests to ensure that the service is working fine as a whole, including the database transactions. Or, if your project is a classical web application, you might have an E2E test suite that utilizes a browser to virtually click through it.</p>
			<p>We want to apply the same approach here that we did for the build steps: start with the fast-running tests, and then continue with the slower ones. If the unit tests are failing already, you do not need to wait for the results of the E2E tests. So, for the tests, the execution order would usually be this:</p>
			<ol>
				<li value="1">Unit tests</li>
				<li>Integration tests</li>
				<li>E2E tests</li>
			</ol>
			<p>If only one test of <a id="_idIndexMarker530"/>whatever type fails, the build will be marked as<a id="_idIndexMarker531"/> failed. If they all pass, we have already passed the most critical part of the pipeline. Our application is ready to be deployed, so now, it is time to clean up and prepare the deliverable.</p>
			<h2 id="_idParaDest-155"><a id="_idTextAnchor156"/>Stage 4 – Deploy</h2>
			<p>Our code has<a id="_idIndexMarker532"/> been checked thoroughly by various tools, and we are <a id="_idIndexMarker533"/>confident that it adheres to our standards. We can now prepare the <strong class="bold">build artifacts</strong> and finally deploy the application. Let us have a look at what needs to be done for this.</p>
			<h3>Gathering data</h3>
			<p>During the<a id="_idIndexMarker534"/> previous stages, all tools we used produced some sort of data, be it through writing to the <strong class="bold">standard output</strong> (<strong class="bold">stdout</strong>), or if you<a id="_idIndexMarker535"/> configured that, by creating reports that summarize the performed actions.</p>
			<p>You can, for example, upload generated reports to dedicated storage or push them to your repository. Or, you can use the code coverage report of PHPUnit and automatically create a code coverage badge from it, which you can add to the README of your GitHub project.</p>
			<p>The most important use case, though, is to debug if any of the stages have failed. You can never have enough debug output in case something goes wrong, so it is a good idea to set the verbosity of your tools to a higher level. Your CI/CD tool usually takes care that everything that was written to the stdout is made available after the execution of the build pipeline.</p>
			<h3>Cleanup</h3>
			<p>Before we <a id="_idIndexMarker536"/>upload the application somewhere, we want to make sure that it does not contain any unnecessary ballast. This includes removing logs or reports from previous stages or deleting the code quality tools. Remember, we should only deploy code to production that is necessary for the application to run—development tools such as PHPUnit are not built with security in mind (<a href="https://phpunit.readthedocs.io/en/9.5/installation.html#webserver">https://phpunit.readthedocs.io/en/9.5/installation.html#webserver</a>).</p>
			<h3>Deploy</h3>
			<p>To<a id="_idIndexMarker537"/> deploy the code to the target environment, we need to wrap it up into an asset that can be easily moved there. This asset is also called a <strong class="bold">deliverable</strong>. The type we choose for the deliverable depends on how the application<a id="_idIndexMarker538"/> has to be deployed to production. A common type for such a deliverable is simply an archive of the code that has to be deployed.</p>
			<p>For example, if your production environment is running on a classic on-premises web server, we need to create an archive of the application code, upload it to the target server, and extract it from there.</p>
			<p>The de facto standard today is a containerized environment using Docker. Once the build instance has been thoroughly tested, a <strong class="bold">Docker image</strong><strong class="bold"><a id="_idIndexMarker539"/></strong> can be created from it. This image will then be <a id="_idIndexMarker540"/>uploaded<a id="_idIndexMarker541"/> to an <strong class="bold">image repository</strong> such as <strong class="bold">Amazon Web Services Elastic Container Repository</strong> (<strong class="bold">AWS ECR</strong>). Such an <strong class="bold">image repository</strong> hosts all your images, so they can be used to spin up new containers when needed. This approach paved the way for highly scalable web applications as we have them today, so designing your application to be <strong class="bold">Dockerizable</strong> from the beginning will pay off if your application, at some point, needs to scale.</p>
			<p class="callout-heading">Containers and images</p>
			<p class="callout">If you are new to Docker, the concept of containers<a id="_idIndexMarker542"/> and images<a id="_idIndexMarker543"/> can be confusing. In short, an image contains all the data, but is read-only and cannot be used alone. To make it usable in the Docker environment, it requires a container that contains all information from the image and offers the required functionality to connect to other containers of your setup. Since you can create as many containers as you need from an image, you can also think of it as a container template.</p>
			<p class="callout">If you want to know more<a id="_idIndexMarker544"/> about Docker, we recommend you check the official documentation at <a href="https://docs.docker.com/get-started/overview">https://docs.docker.com/get-started/overview</a>. There are also tons of tutorials, online courses, and other information to be found on the internet.</p>
			<p>We now have a good idea of what a build pipeline could look like. Before we start setting up our example pipeline, one more thing needs to be clarified—when will it be executed?</p>
			<h2 id="_idParaDest-156"><a id="_idTextAnchor157"/>Integrating the pipeline into your workflow</h2>
			<p>After <a id="_idIndexMarker545"/>setting up all the necessary steps, we finally need to <a id="_idIndexMarker546"/>integrate the pipeline into your workflow. CI/CD tools usually offer you different options on when a pipeline gets executed. In the beginning, this can, of course, be done manually by clicking a button. This is not very comfortable, though. If you use hosted Git repositories such as GitHub, GitLab, or Bitbucket, you can connect them with your build pipeline and start the build whenever a PR was created or a branch got merged into the <strong class="source-inline">main</strong> branch.</p>
			<p>For huge projects where the build takes hours, it is also common to run a build for the current code base at <a id="_idIndexMarker547"/>nighttime (so-called <strong class="bold">nightly builds</strong>). The developers then get their feedback from the pipeline the next day.</p>
			<p>Running a build requires some time, and of course, the developers should not sit in front of the screens and wait until they can continue with their work. They should rather be informed as soon as the build succeeded or failed. All CI/CD tools nowadays offer multiple ways to notify the developer, mostly by email and by messages in chat tools such as Slack or Microsoft Teams. Additionally, they often also offer dashboard views, where you can see the status of all the builds on one screen.</p>
			<p>You now should have a good idea of what a build pipeline could look like for your project. Therefore, it is time to show you a practical example.</p>
			<h1 id="_idParaDest-157"><a id="_idTextAnchor158"/>Building a pipeline with GitHub Actions</h1>
			<p>After learning about all the stages of CI, it is time to practice. Introducing you to all the features of one or more CI/CD tools is out of scope for this book; however, we still want to show you how easy it can be to set up a working build pipeline. To keep the barrier to entry as low as possible for you and to avoid any costs, we have decided to use <strong class="bold">GitHub Actions</strong>.</p>
			<p>GitHub Actions <a id="_idIndexMarker548"/>is not a classic CI tool like Jenkins or CircleCI, but rather a way to build workflows around GitHub repositories. With a bit of creativity, you can do much more than “just” a classical CI/CD pipeline. We will only focus on that aspect, of course.</p>
			<p>You probably already have a GitHub account, and if not, getting one will not cost you anything. You can use GitHub Actions for free up to 2,000 minutes per month at the time of writing for public repositories, which makes it a great playground or a useful tool for your open source projects.</p>
			<p class="callout-heading">Example project</p>
			<p class="callout">We created a small demo application to use during this chapter. You will find it here: <a href="https://github.com/PacktPublishing/Clean-Code-in-PHP/tree/main/ch11/example-application">https://github.com/PacktPublishing/Clean-Code-in-PHP/tree/main/ch11/example-application</a>. Please note that it does not serve any other purpose than demonstrating the basic use of GitHub Actions and Git hooks.</p>
			<h2 id="_idParaDest-158"><a id="_idTextAnchor159"/>GitHub Actions in a nutshell</h2>
			<p>GitHub Actions <a id="_idIndexMarker549"/>offers no fancy user interface where you can configure all stages. Instead, everything is configured via <strong class="bold">YAML Ain’t Markup Language</strong> (<strong class="bold">YAML</strong>) files that are <a id="_idIndexMarker550"/>stored directly in the repository. As a PHP developer, you are most likely experienced with using YAML files for all sorts of configurations—if not, do not worry, as they are easy to understand and use.</p>
			<p>GitHub actions are organized around workflows. A workflow gets triggered by certain events and contains one or more jobs to be executed if the event occurred. A job consists of one or more steps that execute one action each.</p>
			<p>The files have to be stored in the <strong class="source-inline">.github/workflows</strong> folder of a repository. Let us have a look at the first lines of the <strong class="source-inline">ci.yml</strong> file, which will be our CI workflow:</p>
			<pre class="source-code">
name: Continuous Integration
on:
  workflow_dispatch:
  push:
    branches:
      - main
  pull_request:
jobs:
  pipeline:
    runs-on: ubuntu-latest
    steps:
      - name: ...
        uses: ...</pre>
			<p>That is quite some<a id="_idIndexMarker551"/> information already. Let us go through it line by line:</p>
			<ul>
				<li><strong class="source-inline">name</strong> defines how the workflow will be labeled within GitHub and can be any string</li>
				<li><strong class="source-inline">on</strong> states which events should trigger this workflow; these comprise the following:<ul><li><strong class="source-inline">workflow_dispatch</strong> allows us to manually trigger the workflow from the GitHub website, which is great for creating and testing a workflow. Otherwise, we would need to push a commit to main, or create a PR every time.</li><li><strong class="source-inline">push</strong> tells GitHub to execute this workflow whenever a push happens. We narrow it down to pushes on the <strong class="source-inline">main</strong> branch only.</li><li><strong class="source-inline">pull_request</strong> will additionally trigger the workflow on every new PR. The configuration might look a bit incomplete because there is no more information after the colon.</li></ul></li>
				<li><strong class="source-inline">jobs</strong> contains a list of jobs to be executed for this workflow, as detailed here:<ul><li><strong class="source-inline">pipeline</strong> is the <strong class="bold">identifier</strong> (<strong class="bold">ID</strong>) of the only job in this YAML. We chose the word <em class="italic">pipeline</em> to illustrate that we can use GitHub Actions to build our CI/CD pipeline. Note that an ID must consist of one word or several words, concatenated by an underscore (<strong class="source-inline">_</strong>) or a dash (<strong class="source-inline">-</strong>).</li><li><strong class="source-inline">runs-on</strong> tells GitHub to use the latest Ubuntu version as a runner  (that is, as a platform) for this job. Other available platforms are Windows and macOS.</li><li><strong class="source-inline">steps</strong> marks<a id="_idIndexMarker552"/> a list of steps to be executed for this job. In the next section, we will have a closer look at this.</li></ul></li>
			</ul>
			<p>We have the basics of workflow configured now, so we can begin adding the build stages.</p>
			<h2 id="_idParaDest-159"><a id="_idTextAnchor160"/>Stage 1 – Build project</h2>
			<p>The steps are <a id="_idIndexMarker553"/>what makes GitHub Actions so powerful: here, you can choose from a vast amount of already existing <em class="italic">actions</em> to use in your workflow. They are organized in <em class="italic">GitHub Marketplace</em> (<a href="https://github.com/marketplace">https://github.com/marketplace</a>). Let us add some steps to the workflow YAML, as follows:</p>
			<pre class="source-code">
steps:
  ###################
  # Stage 1 - Build #
  ###################
  - name: Checkout latest revision
    uses: actions/checkout@v3
  - name: Install PHP
    uses: shivammathur/setup-php@v2
    with:
      php-version: '8.1'
      coverage: pcov</pre>
			<p>Actions maintained by GitHub are to be found in the <strong class="source-inline">actions</strong> namespace. In our example, this is <strong class="source-inline">actions/checkout</strong>, which is used to check out the repository. We do not need to specify any parameters for now, as this action will automatically use the repository in which this workflow file is located.</p>
			<p>The <strong class="source-inline">@V3</strong> annotation is used to specify the <em class="italic">major</em> version to use. For <strong class="source-inline">actions/checkout</strong>, this would be version <strong class="source-inline">3</strong>. Please note that the latest <em class="italic">minor</em> version is always used, which at the time of writing would be version <strong class="source-inline">3.0.2</strong>.</p>
			<p>The other action, <strong class="source-inline">shivammathur/setup-php</strong>, is provided by one of the many great people who make their work available as open source. For this step, we are using the <strong class="source-inline">with</strong> keyword to specify further parameters. In this example, we use the <strong class="source-inline">php-version</strong> option to have PHP <strong class="source-inline">8.1</strong> installed on the previously selected <em class="italic">Ubuntu</em> machine. Using the <strong class="source-inline">coverage</strong> parameter, we can tell <strong class="source-inline">setup-php</strong> to enable the <strong class="source-inline">pcov</strong> extension for generating code coverage reports.</p>
			<p class="callout-heading">Action parameters</p>
			<p class="callout">Both actions introduced previously offer far more parameters than we can describe here. You can find more information about their functionality by looking them up in <em class="italic">Marketplace</em>.</p>
			<p>Regarding the <a id="_idIndexMarker554"/>formatting, we used comments and blank lines between the steps to make the file more readable. There is no convention, and it is completely up to you how to format your YAML files later.</p>
			<p>The next step is the installation of the project dependencies. For PHP, this usually means running <strong class="source-inline">composer install</strong>. Please note that we <em class="italic">do not</em> use the <strong class="source-inline">--no-dev</strong> option because we need to install the <strong class="source-inline">dev</strong> dependencies to perform all the quality checks. We will remove them at the end of the pipeline again.</p>
			<p class="callout-heading">Dependency management</p>
			<p class="callout">We use the <strong class="bold">Composer</strong> workflow in this chapter as an example to manage our code quality tools, because this is the most common way. However, both other ways of organizing the code quality tools we introduced in <a href="B19050_09.xhtml#_idTextAnchor115"><em class="italic">Chapter 9</em></a><em class="italic">, Organizing PHP Quality Tools,</em> would work with GitHub Actions as well. In that chapter, we also explained the <strong class="source-inline">--no-dev</strong> option in detail.</p>
			<p>This is <a id="_idIndexMarker555"/>what the next steps could look like:</p>
			<pre class="source-code">
- name: Get composer cache directory
  id: composer-cache
  run: echo "::set-output name=dir::$(composer config cache
    files-dir)"
- name: Cache dependencies
  uses: actions/cache@v2
  with:
    path: ${{ steps.composer-cache.outputs.dir }}
    key: ${{ runner.os }}-composer-${{
      hashFiles('**/composer.lock') }}
    restore-keys: ${{ runner.os }}-composer-
- name: Install composer dependencies
  run: composer install</pre>
			<p>GitHub <a id="_idIndexMarker556"/>actions require some manual work to make caching of Composer dependencies possible. In the first step, we store the location of the Composer cache directory, which we get from Composer using the <strong class="source-inline">config cache-files-dir</strong> command, in an output variable called <strong class="source-inline">dir</strong>. Note <strong class="source-inline">id: composer-cache</strong> here—we will need this to reference the variable in the next step.</p>
			<p>Then, we access this variable in the next step by using the <strong class="source-inline">steps.composer-cache.outputs.dir</strong> reference (a combination of the <strong class="source-inline">id</strong> value we set in the previous step, and the variable name) to define the directory that should be cached by the <strong class="source-inline">actions/cache</strong> action. <strong class="source-inline">key</strong> and <strong class="source-inline">restore-key</strong> are used to generate unique caching keys—that is, the cache entries where our Composer dependencies are stored.</p>
			<p>Lastly, we use the <strong class="source-inline">run</strong> parameter to directly execute <strong class="source-inline">composer install</strong>, as if we would execute it locally on an Ubuntu machine. This is important to keep in mind: you can, but you do not have to use existing GitHub actions for every step—you can just execute pure shell commands (or equivalent commands on Windows runners) as well.</p>
			<p>There are also actions in <em class="italic">Marketplace</em> that take over the writing of commands, such as <strong class="source-inline">php-actions/composer</strong>. We do not have a preferred solution here; both will work fine.</p>
			<p>Because we want to run integration tests on the API of our example application, we need to have a web server running. For our simple use case, it is totally enough to use the PHP built-in web server, which we can start using in the following step:</p>
			<pre class="source-code">
- name: Start PHP built-in webserver
  run: php -S localhost:8000 -t public &amp;</pre>
			<p>The <strong class="source-inline">-S</strong> option <a id="_idIndexMarker557"/>tells the PHP binary to start a web server that is listening on the <strong class="source-inline">localhost</strong> address and port <strong class="source-inline">8000</strong>. Since we start in the <strong class="source-inline">root</strong> folder of our project, we need to define a <em class="italic">document root</em> folder (the folder where the web server looks for files to execute) using the <strong class="source-inline">-t</strong> option. Here, we want to use the public folder, which only contains the <strong class="source-inline">index.php</strong> file. It is good practice to not store any other code in the document root folder since this makes it harder for attackers to hack our application.</p>
			<p class="callout-heading">PHP built-in web server</p>
			<p class="callout">Please note that the built-in web server of PHP is only to be used for <em class="italic">development</em> purposes. It should never be used in <em class="italic">production</em>, since it was not built with performance or security in mind.</p>
			<p>You surely noticed the ampersand (<strong class="source-inline">&amp;</strong>) at the end of the command. This tells Linux to execute the command, but not wait for its termination. Without it, our workflow would get stuck at this point because the web server does not terminate by itself, as it needs to keep listening for <a id="_idIndexMarker558"/>requests until we run our <em class="italic">integration tests</em> at a later stage.</p>
			<p>The setup of our build environment is complete. Now, it is time to run the first code quality checks on our sample application.</p>
			<h2 id="_idParaDest-160"><a id="_idTextAnchor161"/>Stage 2 – Code analysis</h2>
			<p>In the first build stage, we created<a id="_idIndexMarker559"/> our build environment and checked out our application code. At this point, the application should be completely functional and ready to be tested. Now, we want to do some static code analysis.</p>
			<p>The standard approach is to use dedicated GitHub actions for each tool. The benefit is that we keep the development tools away from the build environment, as they will be executed in separate Docker containers that will be discarded right after use. There are some drawbacks to this approach, though.</p>
			<p>Firstly, with each action, we introduce yet another dependency, and we rely on the author to keep it up to date and not lose interest in maintaining it after a while. Additionally, we add some overhead, since Docker images are usually many times bigger than the actual tool. And lastly, when our application setup gets more complicated, running the code quality tools in separate Docker containers can cause issues, simply because it is not the same environment as the build environment. Sometimes, already tiny differences can cause problems that keep you engaged for hours or days in solving them.</p>
			<p>As we saw in the previous section, we can simply execute Linux shell commands in the build environment, so nothing speaks against executing our code quality tools directly on the build environment—we just need to make sure to remove them afterward so that they do not get released into production.</p>
			<p>In our example application, we added PHP-CS-Fixer and PHPStan to the <strong class="source-inline">require-dev</strong> section of the <strong class="source-inline">composer.json</strong> file. By adding the following lines of code to our workflow YAML, we will let them execute as the next steps:</p>
			<pre class="source-code">
###########################
# Stage 2 - Code Analysis #
###########################
- name: Code Style Fixer
  run: vendor/bin/php-cs-fixer fix --dry-run
- name: Static Code Analysis
  run: vendor/bin/phpstan</pre>
			<p>We do not need <a id="_idIndexMarker560"/>many parameters or options here, since our example application provides both the <strong class="source-inline">.php-cs-fixer.dist.php</strong> and <strong class="source-inline">phpstan.neon</strong> configuration files, which both tools will look up by default. Only for PHP-CS-Fixer will we use the <strong class="source-inline">--dry-run</strong> option because we only want to check for issues during the CI/CD pipeline, and not solve them.</p>
			<p class="callout-heading">Setting the scope of checks</p>
			<p class="callout">For our small example application, it is OK to run the preceding checks on all files because they will execute quickly. If our application grows, however, or we wish to introduce CI/CD to an existing application (which we will discuss further on in this chapter), it is sufficient to run these checks on those files that have only changed in the latest commit. The following action could be helpful for you in this case: <a href="https://github.com/marketplace/actions/changed-files">https://github.com/marketplace/actions/changed-files</a>.</p>
			<p>If neither PHP-CS-Fixer nor PHPStan reports any issues, we can safely execute the automated tests in the next stage: the tests.</p>
			<h2 id="_idParaDest-161"><a id="_idTextAnchor162"/>Stage 3 – Tests</h2>
			<p>Our code has been <a id="_idIndexMarker561"/>thoroughly analyzed and checked for bugs and syntax errors, yet we need to check for logical errors in our code. Luckily, we have some automated tests to ensure that we did not inadvertently introduce any bugs.</p>
			<p>For the same reasons as for the code quality tools in <em class="italic">Stage 2</em>, we do not want to use a dedicated action for running our PHPUnit test suites. We simply execute PHPUnit as we would on our<a id="_idIndexMarker562"/> local development system. Using the <strong class="source-inline">phpunit.xml</strong> file clearly proves useful here since we do not need to remember all the many options to use here. Let us have a look at the <em class="italic">workflow YAML</em> first, as follows:</p>
			<pre class="source-code">
###################
# Stage 3 - Tests #
###################
- name: Unit Tests
  run: vendor/bin/phpunit --testsuite Unit
- name: Integration Tests
  run: vendor/bin/phpunit --testsuite Api</pre>
			<p>The only thing worth noting here is that we do not just run all tests, but we split them up in two test suites: <strong class="source-inline">Unit</strong> and <strong class="source-inline">Api</strong>. Since our unit tests should execute the fastest, we want to run them (and fail) first, then followed by the slower integration tests. Please note that we did not add any E2E tests as our application does not run in the browser but is a mere web service.</p>
			<p>We split the <a id="_idIndexMarker563"/>tests up by using the <strong class="source-inline">phpunit.xml</strong> configuration file. The following code fragment shows you its <strong class="source-inline">&lt;testsuites&gt;</strong> node, where we separate the suites by their directory (<strong class="source-inline">Api</strong> and <strong class="source-inline">Unit</strong>):</p>
			<pre class="source-code">
&lt;testsuites&gt;
    &lt;testsuite name="Api"&gt;
        &lt;directory&gt;tests/Api&lt;/directory&gt;
    &lt;/testsuite&gt;
    &lt;testsuite name="Unit"&gt;
        &lt;directory&gt;tests/Unit&lt;/directory&gt;
    &lt;/testsuite&gt;
&lt;/testsuites&gt;</pre>
			<p>We also configured PHPUnit to create code coverage reports, as illustrated here:</p>
			<pre class="source-code">
&lt;coverage processUncoveredFiles="false"&gt;
    &lt;include&gt;
        &lt;directory suffix=".php"&gt;src&lt;/directory&gt;
    &lt;/include&gt;
    &lt;report&gt;
        &lt;html outputDirectory="reports/coverage" /&gt;
        &lt;text outputFile="reports/coverage.txt" /&gt;
    &lt;/report&gt;
&lt;/coverage&gt;</pre>
			<p>To create these reports, PHPUnit will automatically use the <strong class="source-inline">pcov</strong> extension, which we configured in <em class="italic">Stage 1</em>. They <a id="_idIndexMarker564"/>will be written into the <strong class="source-inline">reports</strong> folder, which we will take care of in the next stage.</p>
			<p>That is already everything that needs to be done for the tests stage. If our tests did not discover any errors, we are good to go into the last stage of our pipeline and wrap everything up.</p>
			<h2 id="_idParaDest-162"><a id="_idTextAnchor163"/>Stage 4 – Deploy</h2>
			<p>Our application is now<a id="_idIndexMarker565"/> thoroughly checked and tested. Before we are ready to deploy it into whichever environment we envisioned, we need to take care of removing the <strong class="source-inline">dev</strong> dependencies first. Luckily, this is very easy, as we can see here:</p>
			<pre class="source-code">
####################
# Stage 4 - Deploy #
####################
- name: Remove dev dependencies
  run: composer install --no-dev --optimize-autoloader</pre>
			<p>Running <strong class="source-inline">composer install --no-dev</strong> will simply delete all the <strong class="source-inline">dev</strong> dependencies from the <strong class="source-inline">vendor</strong> folder. Another noteworthy feature is the <strong class="source-inline">--optimize-autoloader</strong> option of Composer: since in production, we will not add or change any classes or namespaces as we would do in development, the Composer autoloader can be optimized by not checking for any changes, and thus disk access, speeding it up a bit.</p>
			<p>As the<a id="_idIndexMarker566"/> very last step, we want to create build artifacts: one artifact is the deliverable—that is the code we intend to deploy. The other artifact is the code coverage reports we created in <em class="italic">Stage 3</em>. GitHub Actions will not keep any additional data than the logging information displayed on the GitHub website after the workflow YAML has been executed, so we need to make sure they are stored away at the end. The code is illustrated in the following snippet:</p>
			<pre class="source-code">
- name: Create release artifact
  uses: actions/upload-artifact@v2
  with:
    name: release
    path: |
      public/
      src/
      vendor/
- name: Create reports artifact
  uses: actions/upload-artifact@v2
  with:
    name: reports
    path: reports/</pre>
			<p>We use the <strong class="source-inline">actions/upload-artifacts</strong> action to create two ZIP archives (called <em class="italic">artifacts</em> here): <strong class="source-inline">release</strong> and <strong class="source-inline">reports</strong>. The first contains all files and directories we need to run our application on production, and nothing more. We omit all the configuration files in the root folder of our project, even the <strong class="source-inline">composer.json</strong> and <strong class="source-inline">composer.lock</strong> files. We do not need them anymore, since our <strong class="source-inline">vendor</strong> folder already exists.</p>
			<p>The <strong class="source-inline">reports</strong> artifact <a id="_idIndexMarker567"/>will just contain the <strong class="source-inline">reports</strong> folder. After the build, you can simply download both ZIP archives separately on GitHub. More about this in the next section.</p>
			<h2 id="_idParaDest-163"><a id="_idTextAnchor164"/>Integrating the pipeline into your workflow</h2>
			<p>After adding the <a id="_idIndexMarker568"/>workflow YAML to the <strong class="source-inline">.github/workflows</strong> folder (for example, <strong class="source-inline">.github/workflows/ci.yml</strong>), you only need to commit and<a id="_idIndexMarker569"/> push it to the repository. We configured our pipeline to run upon every opened PR or whenever someone pushes a commit to the <strong class="source-inline">main</strong> branch.</p>
			<p>When you open <a href="https://github.com">https://github.com</a> and go to your repository page, you will find an overview of your last workflow runs on the <strong class="bold">Actions</strong> tab, as shown in the following screenshot:</p>
			<div>
				<div id="_idContainer042" class="IMG---Figure">
					<img src="image/Figure_11.3_B19050.jpg" alt="Figure 11.3: The repository page on github.com&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.3: The repository page on github.com</p>
			<p>The green checkmark <a id="_idIndexMarker570"/>marks the successful runs, while the red <a id="_idIndexMarker571"/>cross—of course—marks the failed ones. You can also see when they were executed and how long this took. By clicking on the three dots on the right side of each entry, you will find more options—for example, where you can delete the workflow run. Clicking on the title of the run, which is the corresponding commit message of the run, you will enter the <strong class="bold">Summary</strong> page, as shown in the following screenshot:</p>
			<div>
				<div id="_idContainer043" class="IMG---Figure">
					<img src="image/Figure_11.4_B19050.jpg" alt="Figure 11.4: The workflow run summary page&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.4: The workflow run summary page</p>
			<p>Here, you can see all<a id="_idIndexMarker572"/> jobs of the workflow. Since our example only<a id="_idIndexMarker573"/> consists of one job, <strong class="source-inline">pipeline</strong>, you will only see one. On this page, you can also find any generated artifacts (such as our release and reports artifacts) and download or delete them. GitHub offers only limited disk space for free, so make sure to delete them when you are running out of space.</p>
			<p>Another important piece of information is the billed time. Although our job only ran for 43 seconds in total, GitHub will deduct 1 minute from your monthly usage. GitHub offers a generous free plan, but you should have a look at your usage from time to time. You can find more information about this on your user settings page in the <strong class="bold">Billing and plans</strong> section (<a href="https://github.com/settings/billing">https://github.com/settings/billing</a>).</p>
			<p>If you want to see what exactly happens during the workflow run—for example, if something goes wrong—you can click on the <strong class="source-inline">pipeline</strong> job to get a detailed overview of all of its steps, as illustrated in the following screenshot:</p>
			<div>
				<div id="_idContainer044" class="IMG---Figure">
					<img src="image/Figure_11.5_B19050.jpg" alt="Figure 11.5: Job details page&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.5: Job details page</p>
			<p>Each step can be <a id="_idIndexMarker574"/>expanded and collapsed to get additional <a id="_idIndexMarker575"/>information about what exactly happened during its execution. In the preceding screenshot, we expanded the <strong class="bold">Install PHP</strong> step to see what the action did in detail.</p>
			<p>Congratulations—you now have a working CI pipeline for your project! This ends our little tour through GitHub Actions. Of course, you can extend the pipeline as you like—for example, by uploading the release artifact to an <strong class="bold">SSH File Transfer Protocol</strong> (<strong class="bold">SFTP</strong>) server<a id="_idIndexMarker576"/> or an <a id="_idIndexMarker577"/>AWS <strong class="bold">Simple Storage Service</strong> (<strong class="bold">S3</strong>) bucket. There is a lot more than can be done, so make sure to experiment with it.</p>
			<p>In the next section, we will show you how you can set up your local pipeline. This will save you some time and probably even costs by avoiding unnecessary workflow runs through early checks.</p>
			<h1 id="_idParaDest-164"><a id="_idTextAnchor165"/>Your local pipeline – Git hooks</h1>
			<p>After we successfully set up a simple but already very useful CI/CD pipeline, we now want to look at running some steps already in the local development environment, even before committing them to the repository. This may sound like double work right now—why should we run the same tools twice?</p>
			<p>Remember <em class="italic">Figure 11.1–Estimated relative costs of fixing a bug based on the time of its detection</em>, from <a id="_idIndexMarker578"/>the beginning of the chapter: the earlier we catch a bug, the fewer costs or the less effort it will cause. Of course, if we find a bug during the CI/CD pipeline, that is still much earlier than in the production environment.</p>
			<p>The pipeline does not come for free, though. Our example application build was fast and just took roughly a minute. Imagine, however, a full-fledged Docker setup that already takes a considerable amount of time to create all the necessary containers. And now, it fails to build just because of a little bug that you could have solved within 2 minutes if you had not forgotten to execute unit tests before committing your code. You might have just taken a well-deserved tea or coffee break, only to find the build failed because of that when you came back. This is annoying and a waste of money as well as computational power.</p>
			<p>Exactly those fast-running checks such as unit tests, a code sniffer, or static code analysis are what we want to execute before we start a full build for our changes. We cannot rely on ourselves to execute these checks automatically because we are humans. We forget things, but machines do not.</p>
			<p>If you use Git for your development, which most developers do today, we can utilize the built-in functionality of<a id="_idIndexMarker579"/> Git hooks to automate these checks. Git hooks are shell scripts that are automatically executed on certain events, such as before or after every commit.</p>
			<p>For our needs, the <em class="italic">pre-commit</em> hook is particularly useful. It will be executed each time you run the <strong class="source-inline">git commit</strong> command and can abort the commit if the executed script returned an error. In this case, no code would be added to the repository.</p>
			<h2 id="_idParaDest-165"><a id="_idTextAnchor166"/>Setting up Git hooks</h2>
			<p>Setting up <a id="_idIndexMarker580"/>Git hooks manually does require some knowledge of shell scripting, so we want to use a package called <strong class="source-inline">CaptainHook</strong> to assist us. Using this tool, we can install any hook we like and even use some advanced features without the need to master Linux.</p>
			<p>You can easily download the Phar by using Phive (see <a href="B19050_09.xhtml#_idTextAnchor115"><em class="italic">Chapter 9</em></a><em class="italic">, Organizing PHP Quality Tools,</em> for more information on that), or use Composer to install it, as we will do now:</p>
			<p class="source-code">$ composer require --dev <strong class="bold">captainhook/captainhook</strong></p>
			<p>Next, we need to create a <strong class="source-inline">captainhook.json</strong> file. This file contains the hook configuration for your project. Since this file will be added to the repository, we ensure that other developers in our team can use it. To create this file, we could run the following command:</p>
			<p class="source-code">$ vendor/bin/captainhook configure</p>
			<p>CaptainHook <a id="_idIndexMarker581"/>will ask you a couple of questions and generate a configuration file based on your answers. You can skip this step, however, and create a file directly, as we will do now. Open your favorite editor, and write the following code:</p>
			<pre class="source-code">
{
    "config": {
        "fail-on-first-error": true
    },
    "pre-commit": {
        "enabled": true,
        "actions": [
            {
             "action": "vendor/bin/php-cs-fixer
               fix --dry-run"
            },
            {
                "action": "vendor/bin/phpstan"
            }
        ]
    }
}</pre>
			<p>Each hook has its own section. Within the <strong class="source-inline">pre-commit</strong> hook section, <strong class="source-inline">enabled</strong> can be either <strong class="source-inline">true</strong> or <strong class="source-inline">false</strong>—the latter disables the hook but keeps the configuration in the file, which can be handy for debugging purposes. <strong class="source-inline">actions</strong> contains the actual commands to execute. As you can see, these commands are like the ones you already know from <a href="B19050_07.xhtml#_idTextAnchor084"><em class="italic">Chapter 7</em></a><em class="italic">, Code Quality Tools</em>.</p>
			<p>Every action you want to have executed needs to be written in a separate action section. In the preceding example, we configured PHP-CS-Fixer and PHPStan to be executed on <strong class="source-inline">pre-commit</strong>.</p>
			<p>Since we have <a id="_idIndexMarker582"/>additional configuration files for both tools, we do not need the specify any further options, except telling PHP-CS-Fixer to only do a dry run—that is, to only inform us when a code style violation has been found.</p>
			<p>In the <strong class="source-inline">config</strong> section, you can specify further configuration parameters. We want to stop the hook execution immediately after an error occurred, so we set <strong class="source-inline">fail-on-first-error</strong> to <strong class="source-inline">true</strong>. Otherwise, CaptainHook would first run all checks, and then tell you the results. This is, of course, just a matter of personal taste.</p>
			<p class="callout-heading">CaptainHook documentation</p>
			<p class="callout">We cannot list all features of CaptainHook<a id="_idIndexMarker583"/> in this book. However, we encourage you to check out the official documentation at <a href="https://captainhookphp.github.io/captainhook">https://captainhookphp.github.io/captainhook</a> to learn more about this tool.</p>
			<p>As we are done now with the configuration, please store this <strong class="bold">JavaScript Object Notation</strong> (<strong class="bold">JSON</strong>) file under the name <strong class="source-inline">captainhook.json</strong> in the project root folder. That is already everything we have to do regarding the configuration.</p>
			<p>We just need to install the hooks now—that is, generate hook files in <strong class="source-inline">.git/hooks</strong>. This can be simply done like so:</p>
			<p class="source-code">$ vendor/bin/captainhook <strong class="bold">install -f</strong></p>
			<p>We use the <strong class="source-inline">-f</strong> option here, which stands for <em class="italic">force</em>. Without this option, CaptainHook would ask us for every hook separately, if we want to install it. Please note that CaptainHook will install a file for every Git hook it supports, even for those which you did not configure. Those hooks will not do anything, though.</p>
			<p>To test the <strong class="source-inline">pre-commit</strong> hook, you can execute this manually without having to commit anything using the following command:</p>
			<p class="source-code">$ vendor/bin/captainhook <strong class="bold">hook:pre-commit</strong></p>
			<p>Similar commands are available for all the other hooks that CaptainHook supports. If you made changes to the <strong class="source-inline">captainhook.json</strong> file, do not forget to install it by using the <strong class="source-inline">install -f</strong> command again.</p>
			<p>To make sure that the<a id="_idIndexMarker584"/> hooks get installed in the local development environment, you can add the following code to the <strong class="source-inline">scripts</strong> section of your <strong class="source-inline">composer.json</strong> file:</p>
			<p class="source-code">"post-autoload-dump": [</p>
			<p class="source-code">    "if [ -e vendor/bin/captainhook ]; then</p>
			<p class="source-code">      vendor/bin/captainhook install -f -s; fi"</p>
			<p class="source-code">]</p>
			<p>We use the <strong class="source-inline">post-autoload-dump</strong> event of Composer to run the <strong class="source-inline">install -f</strong> command. The command will be executed every time the Composer autoloader gets refreshed, which will happen every time <strong class="source-inline">composer install</strong> or <strong class="source-inline">composer update</strong> is executed. This way, we make sure that the hooks are installed or updated regularly in the development environments of anybody who works on this project. By using <strong class="source-inline">if [ -e vendor/bin/captainhook ]</strong>, we check if the CaptainHook binary exists and avoid breaking the CI build if it is not installed.</p>
			<h2 id="_idParaDest-166"><a id="_idTextAnchor167"/>Git hooks in practice</h2>
			<p>We completed the <a id="_idIndexMarker585"/>configuration of the <strong class="source-inline">pre-commit</strong> hook and tested and installed it. Now, we are ready to see it in action: if you do any change in the application code—for example, by adding a blank line somewhere in the <strong class="source-inline">ProductController.php</strong> file—and then try to commit the changes, the <strong class="source-inline">pre-commit</strong> hook should be executed. If the changes violated the <em class="italic">PSR-12</em> standard, the PHP-CS-Fixer step should fail, as shown in the following screenshot:</p>
			<div>
				<div id="_idContainer045" class="IMG---Figure">
					<img src="image/Figure_11.6_B19050.jpg" alt="Figure 11.6: The pre-commit hook fails&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.6: The pre-commit hook fails</p>
			<p class="callout-heading">Fixing code style issues automatically</p>
			<p class="callout">Of course, you can remove the <strong class="source-inline">--dry-run</strong> option when executing PHP-CS-Fixer to let it fix issues automatically. In fact, this is a common practice, and we encourage you to try out the same. However, it requires a bit more work, because you must let the user know that their changed files have been fixed and that they need to be re-committed. To keep this example simple, we decided to omit this.</p>
			<p>We now know that the <strong class="source-inline">ProductController.php</strong> file has to be fixed. We can let PHP-CS-Fixer do the work, as demonstrated here:</p>
			<div>
				<div id="_idContainer046" class="IMG---Figure">
					<img src="image/Figure_11.7_B19050.jpg" alt="Figure 11.7: Using PHP-CS-Fixer to automatically fix code style issues&#13;&#13;&#10;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.7: Using PHP-CS-Fixer to automatically fix code style issues</p>
			<p><strong class="source-inline">ProductController.php</strong> has been <a id="_idIndexMarker586"/>changed again now, and those additional changes have not yet been staged—that is, they have not yet been added to the commit. The previous changes are still staged, though. The following screenshot shows you what it would look like if you ran <strong class="source-inline">git status</strong> at this point:</p>
			<div>
				<div id="_idContainer047" class="IMG---Figure">
					<img src="image/Figure_11.8_B19050.jpg" alt="Figure 11.8: Unstaged changes&#13;&#13;&#10;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.8: Unstaged changes</p>
			<p>All that needs to be done now is to add the <strong class="source-inline">ProductController.php</strong> file again and run <strong class="source-inline">git commit</strong> again, as demonstrated in the following screenshot:</p>
			<div>
				<div id="_idContainer048" class="IMG---Figure">
					<img src="image/Figure_11.9_B19050.jpg" alt="Figure 11.9: pre-commit hook passes&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.9: pre-commit hook passes</p>
			<p>Both steps of<a id="_idIndexMarker587"/> the <strong class="source-inline">pre-commit</strong> hook pass now. All you need to do now is to <strong class="source-inline">git push</strong> the committed changes.</p>
			<h2 id="_idParaDest-167"><a id="_idTextAnchor168"/>Advanced usage</h2>
			<p>The preceding example was a <a id="_idIndexMarker588"/>very basic one. Of course, there is much more that you can do in the local development environment already. You could, for example, add more tools such as the <strong class="source-inline">phpcpd</strong> copy and paste detector or the <strong class="source-inline">phpmd</strong> mess detector, both of which we introduced in <a href="B19050_07.xhtml#_idTextAnchor084"><em class="italic">Chapter 7</em></a><em class="italic">, Code Quality Tools</em>.</p>
			<p>If your tests are not too slow (what exactly that means depends on your and your teammates’ patience), you should consider running your tests locally as well. Even if you have slow-running tests, you can separate them into several test suites, and only execute the fast-running tests on <strong class="source-inline">pre-commit</strong>.</p>
			<p>You should also consider running code quality checks on modified files only and not the whole project, as we did in our <a id="_idIndexMarker589"/>example. CaptainHook provides the useful <strong class="source-inline">{$STAGED_FILES}</strong> placeholder, which contains all staged files. It is very convenient to use, as we can see here:</p>
			<p class="source-code">{</p>
			<p class="source-code">    "pre-commit": {</p>
			<p class="source-code">        "enabled": true,</p>
			<p class="source-code">        "actions": [</p>
			<p class="source-code">            {</p>
			<p class="source-code">                "action": "vendor/bin/php-cs-fixer fix</p>
			<p class="source-code">                  <strong class="bold">{$STAGED_FILES|of-type:php}</strong> --dry-run"</p>
			<p class="source-code">            },</p>
			<p class="source-code">            {</p>
			<p class="source-code">                "action": "vendor/bin/phpstan analyse</p>
			<p class="source-code">                  <strong class="bold">{$STAGED_FILES|of-type:php}"</strong></p>
			<p class="source-code">            }</p>
			<p class="source-code">        ]</p>
			<p class="source-code">    }</p>
			<p class="source-code">}</p>
			<p>The preceding<a id="_idIndexMarker590"/> example runs the checks only on modified PHP files. This has two main benefits: firstly, it is faster because you do not have to check code that you have not touched. The speedup, of course, depends on the size of your code base.</p>
			<p>Secondly, especially if you are working on an existing project and just started introducing these checks, running them on the whole code base is not an option because you would <a id="_idIndexMarker591"/>need to fix too many files at once. We will discuss this in more detail in the next section.</p>
			<h1 id="_idParaDest-168"><a id="_idTextAnchor169"/>Excursion – Adding CI to existing software</h1>
			<p>If you work <a id="_idIndexMarker592"/>in a company, you will not always start <em class="italic">on the green</em>—that is, build a new project from the ground up. In fact, most likely it will be the opposite: when you join a company, you will be added to a team that has been working on one or more projects for a long time already.</p>
			<p>You probably came across the terms <em class="italic">legacy software</em> or <em class="italic">legacy system</em> already. In our context, they describe software<a id="_idIndexMarker593"/> that has existed for a long time and is still in use in business-critical processes. It does not meet modern development standards anymore, so it cannot be easily updated or changed. Over time, it becomes so brittle and hard to maintain that no developer wants to touch it anymore. What makes it even worse is the fact that because the system grew over a longer time, it has so much functionality that no stakeholder (that is, the users) would like to miss it. So, replacing a legacy system is not that easy.</p>
			<p>Not surprisingly, legacy software has a bad connotation, yet probably, all the system needs is some “attention”. Think of it like the restoration of an old machine, where old parts get replaced with modern ones, while the outside is left unchanged. Some developers even find it extra challenging to work on such software. It has come a long way, earned its money, and—most likely (at least partly)—pawed the success of the company, so it deserves some respect.</p>
			<p>So, if you have to work on such a project, do not give up quickly. With this book, we provided you with the necessary knowledge and tools to start bringing it into shape again—it just will take a bit longer, and you might never reach a perfect level. But being perfect is not necessary anyway.</p>
			<h2 id="_idParaDest-169"><a id="_idTextAnchor170"/>Step by step</h2>
			<p>Start with adding integration and E2E tests. Both test types usually require no or just a few changes on the code but will bring great benefit, as they indirectly cover a lot of code without having to write unit tests. Once you’ve covered the critical paths (that is, the most used workflows) of the application with tests, you can start refactoring the classes and start introducing additional unit tests. The tests will help you to discover bugs and side effects quickly, without having to click through the application repeatedly.</p>
			<p>Introducing a code style<a id="_idIndexMarker594"/> such as <em class="italic">PSR-12</em> is, as you know by now, as easy as just running a tool <a id="_idIndexMarker595"/>such as <strong class="source-inline">PHP-CS-Fixer</strong> over the entire code base at once. The resulting commit will, of course, be huge, so you want to agree upon a code freeze with any fellow developers before you do it. A code freeze means that everybody commits their changes into the repository so that your refactoring does not cause huge merge conflicts when they check out the changes afterward.</p>
			<p>To decide which code to refactor, we intend to use one or more of the many code quality tools you know by now. Going with PHPStan on level <strong class="source-inline">0</strong> is a good choice. You might also want to consider Psalm, as it can also resolve some issues automatically. Depending on the size of the project, the list of errors can be dauntingly long. Making use of the baseline feature, as described in <a href="B19050_07.xhtml#_idTextAnchor084"><em class="italic">Chapter 7</em></a>,<em class="italic"> Code Quality Tools</em>, can be a cosmetic help here, but it will only hide and not solve the code issues.</p>
			<p>You do not need to rush. If you configure your CI/CD pipeline to only check modified files, you can start improving the code over time, piece by piece. It does leave you with the problem that once you have touched a file, you must refactor it to meet the rules. Especially for old but huge classes, this can be problematic. In <a href="B19050_07.xhtml#_idTextAnchor084"><em class="italic">Chapter 7</em></a>, <em class="italic">Code Quality Tools</em>, however, we explained how you can exclude files or parts of the code from the performed checks. You can even set up a pipeline that allows you to skip the checks upon a certain keyword (for example, <strong class="source-inline">skip ci</strong>) in the commit message. This approach, however, should only be the last resort—otherwise, you will never start refactoring old code. It takes some self-restraint from the developers not to misuse this feature, too.</p>
			<p>Over time, the team working on the project will gather new confidence, and with growing test coverage, they will start refactoring more and more code. Make sure to install a local pipeline as well, to keep the waiting times short.</p>
			<h1 id="_idParaDest-170"><a id="_idTextAnchor171"/>An outlook on CD</h1>
			<p>Eventually, your CI <a id="_idIndexMarker596"/>pipeline will work so well that you can fully trust it. It will prevent shipping broken code into production reliably, and at some point, you find yourself doing fewer and less-manual checks if the deployment went well. At that point, you could think about using CD: this describes the combination of tools and processes to deploy code to any environment automatically.</p>
			<p>A usual workflow is that whenever changes get merged into a certain branch (for example, <strong class="source-inline">main</strong> for the production environment), the CI/CD pipeline will be triggered automatically. If the changes pass all checks and tests, the process is trusted so much that the code gets deployed into the desired destination without testing the build result manually anymore.</p>
			<p>If you ever had the opportunity to work in such an environment, you surely do not want to miss it. Besides a great CI/CD pipeline<a id="_idIndexMarker597"/> and 99% trust in it, it requires some more processes in place to quickly react if a deployment has problems. Even the best tools cannot prevent logical errors or infrastructural issues that will only appear under a greater load.</p>
			<p>Whenever there is a problem after deployment, your team should be the first ones to notice! You not only need to fully trust the pipeline but the monitoring and logging setup as well. There are many concepts and tools out there, and we are finally leaving the topic of code quality here, entering the realms of <strong class="bold">development-operations</strong> (<strong class="bold">DevOps</strong>) and<a id="_idIndexMarker598"/> system administration. Nevertheless, we want to give you some short guidance on a few key concepts you might want to delve into, as follows:</p>
			<ul>
				<li><strong class="bold">Monitoring</strong> gathers<a id="_idIndexMarker599"/> information about the status of a system. In our context, this is usually information such as <strong class="bold">central processing unit</strong> (<strong class="bold">CPU</strong>) load, <strong class="bold">random-access memory</strong> (<strong class="bold">RAM</strong>) usage, or database traffic of all servers or instances. For example, if the CPU load suddenly increases massively, this is an excellent indicator that there is trouble ahead.</li>
				<li><strong class="bold">Logging</strong> helps you <a id="_idIndexMarker600"/>organize all log messages your application produces in a single, easily accessible place. It is not helpful if you need to search for any log files on different servers first when the system is in trouble and all alerts are ringing.</li>
				<li>There are multiple <strong class="bold">deployment methods</strong> available. Especially when your setup has grown and consists of multiple <a id="_idIndexMarker601"/>servers or cloud instances, you can roll out the new code just on a few instances or even a separate deploy environment and monitor the behavior there. If all goes well, you can continue the deploy to the remaining instances. These methods are called <strong class="bold">canary</strong>, <strong class="bold">rolling</strong>, and <strong class="bold">blue/green</strong> deployments. You <a id="_idIndexMarker602"/>will find a link with more <a id="_idIndexMarker603"/>information on them at the end of this<a id="_idIndexMarker604"/> chapter.</li>
				<li>Regardless of how well you monitor your software, if things go wrong (and they will), you need to go back to a previous version of your application. This is called a <strong class="bold">rollback</strong>. You <a id="_idIndexMarker605"/>should always be prepared to go back to the previous version as fast and easy as possible. This requires you to have the deliverables of several previous versions available. It is a good idea to keep at least 5 or 10 versions because sometimes, it is not clear which version exactly caused the problem.</li>
			</ul>
			<p>Surely, CD is beyond the scope of writing clean PHP code. However, we think it is a goal worth aiming for, as it will speed up your development a lot, and introduces you to a variety of fascinating tools and concepts.</p>
			<h1 id="_idParaDest-171"><a id="_idTextAnchor172"/>Summary</h1>
			<p>We hope that, after reading this chapter, you are as convinced as we are that CI is extremely helpful and thus a must-have tool in your toolbox. We explained the necessary terms around this topic as well as the different stages of a pipeline, not only in theory but also in practice, by building a simple but working pipeline using GitHub Actions. Finally, we gave you an outlook on CD.</p>
			<p>You now have a great foundation of knowledge and tools to write great PHP code. Of course, learning never stops, and there is so much more knowledge out there for you to discover that we could not fit into this book.</p>
			<p>If you made developing PHP software your profession, then you usually work in teams of developers. And even if you are maintaining your own open source project, you will interact with others—for example, when they submit changes to your code. CI is an important building block, but not the only thing you need to consider for a successful team setup.</p>
			<p>For us, this topic is so important that we dedicated the next two chapters to introducing modern collaboration techniques that will help you to write great PHP code when working in teams. We hope to see you in the next chapter!</p>
			<h1 id="_idParaDest-172"><a id="_idTextAnchor173"/>Further reading</h1>
			<p>If you wish to know more, have a look at the following resources:</p>
			<ul>
				<li>Additional information about GitHub Actions:<ul><li>The official <em class="italic">GitHub Actions</em> documentation with lots of examples: <a href="https://docs.github.com/en/actions">https://docs.github.com/en/actions</a></li><li><strong class="source-inline">setup-php</strong> is not only very useful for PHP developers, but also offers a lot of useful information—for example, about the <em class="italic">matrix setup</em> (how to test code against several PHP versions) or <em class="italic">caching Composer dependencies</em> to speed up the build: <a href="https://github.com/marketplace/actions/setup-php-action">https://github.com/marketplace/actions/setup-php-action</a></li></ul></li>
				<li>More information about CD and related topics can be found here:<ul><li>A good overview of CD: <a href="https://www.atlassian.com/continuous-delivery">https://www.atlassian.com/continuous-delivery</a></li><li>Logging and monitoring explained: <a href="https://www.vaadata.com/blog/logging-monitoring-definitions-and-best-practices/">https://www.vaadata.com/blog/logging-monitoring-definitions-and-best-practices/</a></li><li>A great introduction to advanced deployment methods: <a href="https://www.techtarget.com/searchitoperations/answer/When-to-use-canary-vs-blue-green-vs-rolling-deployment">https://www.techtarget.com/searchitoperations/answer/When-to-use-canary-vs-blue-green-vs-rolling-deployment</a></li></ul></li>
				<li>Tools and links regarding your local pipeline:<ul><li>More insights on Git hooks: <a href="https://git-scm.com/book/en/v2/Customizing-Git-Git-Hooks">https://git-scm.com/book/en/v2/Customizing-Git-Git-Hooks</a></li><li>GrumPHP is a local CI pipeline “out of the box”: <a href="https://github.com/phpro/grumphp">https://github.com/phpro/grumphp</a></li></ul></li>
			</ul>
		</div>
		<div>
			<div id="_idContainer050">
			</div>
		</div>
	</body></html>