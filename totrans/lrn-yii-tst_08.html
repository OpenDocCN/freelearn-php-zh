<html><head></head><body><div class="chapter" title="Chapter&#xA0;8.&#xA0;Analyzing Testing Information"><div class="titlepage"><div><div><h1 class="title"><a id="ch08"/>Chapter 8. Analyzing Testing Information</h1></div></div></div><p>In the last three chapters, we covered the topic of writing tests at different levels: unit, functional, and acceptance. So far, we have tested the new interface that we created, and we learned to apply all the new methods. This was a relatively easy task, but we don't know how good we did in our testing. There are some specific metrics that we can analyze to generate a direct and immediate report on the quality of the tests. These reports will help us in taking informed decisions regarding the architecture of our code.</p><p>Codeception is bundled with most of these report generation tools, and it's quite easy as it's been until now.</p><p>In this chapter, we will primarily cover the code coverage metrics, and we'll briefly touch on some other metrics, which can be obtained through various software.</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Improving the quality of your tests</li><li class="listitem" style="list-style-type: disc">Improving our code with the aid of additional tools</li></ul></div><div class="section" title="Improving the quality of your tests"><div class="titlepage"><div><div><h1 class="title"><a id="ch08lvl1sec43"/>Improving the quality of your tests</h1></div></div></div><p>Since the beginning<a id="id399" class="indexterm"/> of programming and, in particular, testing, many programmers started questioning themselves on what it means to write good tests, or in other words, how do I know that the test I have written is good? What are the metrics for this?</p><p>It's definitely not a question of personal preference or skill.</p><p>One of the first methods that was created for analyzing the quality of the tests was called code coverage. From a wider perspective, code coverage measures how much of the code is covered by the tests. There is a correlation between software bugs and the test code coverage, where the software with more code coverage has fewer bugs, although the tests won't remove the possibility of bugs being introduced, for instance, as a manifestation of complex interactions between modules or unexpected inputs and corner cases. This is why you need to be careful when planning and designing your tests, and you need to take into consideration that this won't remove the need for regression and exploratory testing, at least, not entirely.</p><p>There are several code coverage criteria<a id="id400" class="indexterm"/> that are normally used for the code coverage programs.</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Line coverage</strong></span>: This is <a id="id401" class="indexterm"/>based on the number of executable lines that were executed.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Function and method coverage</strong></span>: This<a id="id402" class="indexterm"/> calculates the number of functions or methods that were executed.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Class and trait coverage</strong></span>: This <a id="id403" class="indexterm"/>measures the covered classes and traits when all of their methods are executed.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Opcode coverage</strong></span>: This<a id="id404" class="indexterm"/> is similar to line coverage, although a single line might generate more than one opcode. The line coverage considers a line to have been covered as soon as one of its opcodes are executed.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Branch coverage</strong></span>: This <a id="id405" class="indexterm"/>measures if each possible combination of Boolean expression in the control structures are being evaluated when the tests are run.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Path coverage</strong></span>: This<a id="id406" class="indexterm"/> is also called <span class="strong"><strong>Decision-to-Decision</strong></span> (<span class="strong"><strong>DD</strong></span>) path, and it considers all the possible execution paths, in terms of its unique sequence of branch execution from the beginning to the end of each method or function.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Change Risk Anti-Patterns</strong></span> (<span class="strong"><strong>C.R.A.P.</strong></span>) <span class="strong"><strong>Index</strong></span>: This <a id="id407" class="indexterm"/>is based on the cyclomatic complexity and the code coverage of a unit of code. This index can be lowered by refactoring the code or by incrementing the number of tests. Either way, it's primarily used for unit tests.</li></ul></div><p>Since Codeception uses PHP_CodeCoverage, it does not support opcode coverage, branch coverage, and path coverage.</p><p>With this in mind, if we go back to our unit tests, we will understand a bit better the structure of our tests and how they are currently working.</p><p>Let's start by enabling the code coverage in our unit tests and then looking  at their results.</p><p>Later, we will look at the functional and acceptance coverage reports, and then explore some other interesting information, which we can extract from our code.</p><div class="section" title="Enabling code coverage in Codeception"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec62"/>Enabling code coverage in Codeception</h2></div></div></div><p>Codeception <a id="id408" class="indexterm"/>provides a global and a specific configuration for code coverage. Depending on the structure of your application and the type of test you are going to implement based on your test plan, you can have either a generic configuration in <code class="literal">/tests/codeception.yml,</code> or a specific configuration for each suite configuration file, such as <code class="literal">/tests/codeception/unit.suite.yml</code>. You can also have both of these configurations. However, in this case, the single suite configuration will override the setting of the global configuration.</p><p>We are going to use the global configuration file. So at the end of the file, append the following lines:</p><div class="informalexample"><pre class="programlisting"># tests/codeception.yml

coverage:
    enabled: true
    white_list:
        include:
            - ../models/*
            - ../modules/v1/controllers/*
            - ../controllers/*
            - ../commands/*
            - ../mail/*
    blacklist:
        include:
            - ../assets/*
            - ../build/*
            - ../config/*
            - ../runtime/*
            - ../vendor/*
            - ../views/*
            - ../web/*
            - ../tests/*</pre></div><p>This should be enough for getting started. The first option enables the code coverage, while the rest of the options tell Codeception and the code coverage program which files to include when writing the report for the white list and the black list. This will ensure that the results aggregate the information that is relevant to us, in other words, what we've written, rather than the framework itself.</p><p>We won't need<a id="id409" class="indexterm"/> to run the <code class="literal">build</code> command of Codeception, as there isn't a new module that has to be imported into our tester guys.</p><p>If we look at the <code class="literal">help</code> option for the <code class="literal">run</code> action of Codeception, then we will notice that it has two main options for generating the reports that we are interested in.</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">--coverage</code>: This <a id="id410" class="indexterm"/>generates the actual coverage report, and it is accompanied by a series of other options for controlling the format and the verbosity of the report</li><li class="listitem" style="list-style-type: disc"><code class="literal">--report</code>: This <a id="id411" class="indexterm"/>generates an overall report of the tests that were run</li></ul></div><p>In conjunction with these two options, we will be able to generate the HTML and XML test and coverage reports, depending on the use. In particular, the XML report will be quite handy when we get to <a class="link" href="ch09.html" title="Chapter 9. Eliminating Stress with the Help of Automation">Chapter 9</a>, <span class="emphasis"><em>Eliminating Stress with the Help of Automation</em></span>.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note30"/>Note</h3><p>It's important to keep in mind that currently the coverage reports of the acceptance tests are not merged with the reports generated for the functional and unit tests. This is due to the way in which the code coverage is calculated and intercepted. Later, we will see what will be needed for generating the coverage reports for acceptance tests.</p></div></div></div><div class="section" title="Extracting the code coverage information for unit tests"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec63"/>Extracting the code coverage information for unit tests</h2></div></div></div><p>In the <a id="id412" class="indexterm"/>Codeception documentation, this is normally referred to as the <a id="id413" class="indexterm"/>
<span class="strong"><strong>local coverage</strong></span> report and it is applied to both the unit and functional tests. We'll touch upon remote coverage when talking about the coverage for acceptance tests.</p><p>We can easily generate the coverage by appending the <code class="literal">--coverage</code> flag to the command shown here:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ ../vendor/bin/codecept run unit --coverage</strong></span>
</pre></div><p>This will end with an output similar to the following:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>...</strong></span>
<span class="strong"><strong>Time: 44.93 seconds, Memory: 39.75Mb</strong></span>

<span class="strong"><strong>OK (32 tests, 68 assertions)</strong></span>
<span class="strong"><strong>Code Coverage Report:     </strong></span>
<span class="strong"><strong>  2015-01-05 21:43:13     </strong></span>
<span class="strong"><strong>                          </strong></span>
<span class="strong"><strong> Summary:                 </strong></span>
<span class="strong"><strong>  Classes: 25.00% (2/8)   </strong></span>
<span class="strong"><strong>  Methods: 45.00% (18/40)</strong></span>
<span class="strong"><strong>  Lines:   26.42% (56/212)</strong></span>

<span class="strong"><strong>\app\models::ContactForm</strong></span>
<span class="strong"><strong>  Methods:  33.33% ( 1/ 3)   Lines:  80.00% ( 12/ 15)</strong></span>
<span class="strong"><strong>\app\models::Dog</strong></span>
<span class="strong"><strong>  Methods: 100.00% ( 2/ 2)   Lines: 100.00% (  3/  3)</strong></span>
<span class="strong"><strong>\app\models::LoginForm</strong></span>
<span class="strong"><strong>  Methods: 100.00% ( 4/ 4)   Lines: 100.00% ( 18/ 18)</strong></span>
<span class="strong"><strong>\app\models::User</strong></span>
<span class="strong"><strong>  Methods:  84.62% (11/13)   Lines:  79.31% ( 23/ 29)</strong></span>
</pre></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note31"/>Note</h3><p>The execution time you see here is based on a machine with an i7-m620 processor, on which runs the Linux kernel. The coverage increases the time exponentially. On the same machine, running the unit tests takes less than 10 seconds.</p><p>There are methods for shortening the execution time. This can be done by using Robo, which is a task runner, and its specific Codeception plugin is robo-paracept. More information can be found in the official Codeception documentation at <a class="ulink" href="http://codeception.com/docs/12-ParallelExecution">http://codeception.com/docs/12-ParallelExecution</a>.</p></div></div><p>This report<a id="id414" class="indexterm"/> gives us a succinct and immediate output of the code coverage of our unit tests.</p><p>The coverage for classes, methods, and lines (and where the percentage is calculated from), and a slightly detailed breakdown per class can be seen from the summary.</p><p>We can see that we succeeded in covering 100 percent of the <code class="literal">Dog</code> and <code class="literal">LoginForm</code> classes, and we nonetheless achieved a good 84.62 percent of the methods of the <code class="literal">User</code> class, but disappointingly, we covered only 33.33 percent of the methods of the <code class="literal">ContactForm</code>.</p><p>But, what did we miss?</p><p>Well, there's only one<a id="id415" class="indexterm"/> way to find out, and that is by generating the HTML coverage report.</p></div><div class="section" title="Generating a detailed coverage report of the unit tests"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec64"/>Generating a detailed coverage report of the unit tests</h2></div></div></div><p>With <a id="id416" class="indexterm"/>the help of the <code class="literal">--coverage-html</code> option, we can generate a detailed code coverage report. Then, we can inspect it in order to understand what was covered and what was missed:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ ../vendor/bin/codecept run unit --coverage-html</strong></span>
</pre></div><p>This will now end with the following output line:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>HTML report generated in coverage</strong></span>
</pre></div><p>The report will be saved in the <code class="literal">_output/coverage/</code> directory, where you will find two files: <code class="literal">dashboard.html</code> and <code class="literal">index.html</code>. The first gives you some nice graphs, which are a little more interesting than the coverage report summary printed on the console, but it is mostly used for showing off and it is not useful for understanding what's wrong with the tests. There's, in fact, an open request for suppressing this output on the console (<a class="ulink" href="https://github.com/Codeception/Codeception/issues/1592">https://github.com/Codeception/Codeception/issues/1592</a>).</p><div class="mediaobject"><img src="graphics/B03646_08_06.jpg" alt="Generating a detailed coverage report of the unit tests"/><div class="caption"><p>Details of the <span class="strong"><strong>Insufficient Coverage</strong></span> panel on the dashboard</p></div></div><p>As you can see from the preceding screenshot, the bit that you might be interested in at this level of detail is the <span class="strong"><strong>Insufficient Coverage</strong></span> panel, (currently) sitting at bottom-left of the page.</p><p>We will discuss the other panels later.</p><p>You will be <a id="id417" class="indexterm"/>really interested in the <code class="literal">index.html</code> file. From there, you can see some of the detailed statistics and you can dig into every single file that has been analyzed, to see what lines the tests have covered and so improve your tests from there.</p><div class="mediaobject"><img src="graphics/B03646_08_01.jpg" alt="Generating a detailed coverage report of the unit tests"/><div class="caption"><p>Summary of the coverage across all files analyzed</p></div></div><p>The summary of the coverage shows what's been covered, in some detail. This helped us in discovering immediately what was wrong with our testing, and in our case, one of the tests provided by Yii for <code class="literal">ContactForm</code> was not covered sufficiently. In the preceding screenshot, we can see that it shows 80 percent coverage of lines, 33.33 percent coverage of the methods, but it does not show anything regarding the classes. This is because, unless you have all the methods covered, you won't have the class marked as covered.</p><p>This may not <a id="id418" class="indexterm"/>prove be a problem. There are methods that are not a part of our implementation and these can only be tested by using an integration test, and then there are others that can be covered by paying a bit of attention. If we click on the <span class="strong"><strong>ContactForm.php</strong></span> link, then we would see the following:</p><div class="mediaobject"><img src="graphics/B03646_08_02.jpg" alt="Generating a detailed coverage report of the unit tests"/><div class="caption"><p>Summary of the coverage of the code in the selected file</p></div></div><p>Of the two methods that have not been covered, we don't really need to cover the first method, <code class="literal">attributeLabels()</code>. Technically, this is because of two reasons: the first reason is that as it is a part of the Yii framework, we assume that it will work; the second reason is that it's a trivial method, and it always returns an internal variable, which can't be controlled in any way.</p><p>The other method is the <code class="literal">contact()</code> method and it has been covered partially. So, we're going to fix this. It may well be possible that this specific test will get corrected in a future version of the framework. This might be something that you need to look out for.</p><p>By clicking on the <span class="strong"><strong>contact($email)</strong></span> link, or by just scrolling to the bottom of the page, we will find our method, and this will show us that all the paths have not been covered.</p><div class="mediaobject"><img src="graphics/B03646_08_03.jpg" alt="Generating a detailed coverage report of the unit tests"/><div class="caption"><p>Discovering what needs to be covered with the aid of color coded lines</p></div></div><p>Our case is <a id="id419" class="indexterm"/>quite simple, so we will try to fix these errors either by adding the <code class="literal">@codeCoverageIgnore</code> directive to the documentation of the method that we want to exclude, or by adjusting or adding a new test to it in order to reach as close as possible to 100 percent. Remember, this is what we will be aiming for, but this is not necessarily our target.</p><div class="informalexample"><pre class="programlisting">// /tests/codeception/unit/models/ContactFormTest.php

/**
 * @return array customized attribute labels
 * <span class="strong"><strong>@codeCoverageIgnore</strong></span>
 */
public function attributeLabels()
{
    return [
        'verifyCode' =&gt; 'Verification Code',
    ];
}</pre></div><p>The solution to<a id="id420" class="indexterm"/> cover the remaining branch of the <code class="literal">if</code> statement is to add a test similar to the following:</p><div class="informalexample"><pre class="programlisting">// /tests/codeception/unit/models/ContactFormTest.php

public function testContactReturnsFalseIfModelDoesNotValidate()
{
    $model = $this-&gt;getMock(
          'app\models\ContactForm', ['validate']
    );
    $model-&gt;expects($this-&gt;any())
          -&gt;method('validate')
          -&gt;will($this-&gt;returnValue(false));

    $this-&gt;specify('contact should not send', function () use (&amp;$model) {
        expect($model-&gt;contact(null), false);
        expect($model-&gt;contact('admin@example.com'), false);
    });

}</pre></div><p>Now, let's run our tests again, and we will see the screenshot shown here:</p><div class="mediaobject"><img src="graphics/B03646_08_04.jpg" alt="Generating a detailed coverage report of the unit tests"/><div class="caption"><p>We've reached 100 percent coverage! Yay!</p></div></div><p>I'll leave it to you to<a id="id421" class="indexterm"/> fix the remaining errors. Certain situations might be hard to cover, and you may need additional hints and suggestions on how to restructure your tests.</p></div><div class="section" title="Aggregating functional tests to unit tests"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec65"/>Aggregating functional tests to unit tests</h2></div></div></div><p>Now that<a id="id422" class="indexterm"/> we've seen what is going on in our unit tests and how to visually understand if we have effectively covered as much as we could, we can move to the functional tests that we wrote previously.</p><p>As we saw earlier, we can just add the functional suite to the command line for generating the aggregated reports.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ ../vendor/bin/codecept run unit,functional --coverage</strong></span>
</pre></div><p>We will also see that by omitting the suites we will end up with the same result, but we don't know when the Codeception developers will merge all the three suites into a single coverage report, so just keep this in mind and consult the documentation.</p><p>Our unit tests have covered the models in their entirety. Our functional tests should focus on the controllers. You should be able to spot that the login page and the REST module controller have not been covered completely. So, let's discuss these one by one.</p><p>The login page will display the missing coverage for the login and the logout action.</p><p>In the first case, it seems pretty easy to cover that. We have to make sure that we reach that action after logging in. So, let's add the following assertion right after the successful login at the end of the test file:</p><div class="informalexample"><pre class="programlisting">// tests/codeception/functional/LoginCept.php

$I-&gt;amGoingTo('ensure I cannot load the login page if I am logged in');
$I-&gt;amOnPage('/index-test.php/login');
$I-&gt;seeCurrentUrlEquals('/index-test.php');</pre></div><p>As we can <a id="id423" class="indexterm"/>see, we're using a few specific paths for testing the website. This isn't a problem when interacting with the Codeception REST module, but here we have to be verbose.</p><p>The other portion that we have to cover is a little more complex. Once we are logged in, notice that the logout button has a JS click event attached to it, and that will send a POST request to <code class="literal">/logout</code>.</p><p>Since PHPBrowser won't be able to read JS, nor will it have the ability to do a specific POST call, we won't be able to cover this piece of code. Don't even think about using <code class="literal">sendPost()</code> as it's a specific method, which comes from the REST module of Codeception.</p><p>The only solution for this is to leave the coverage of this bit to the acceptance tests or to WebDriver.</p><p>Due to the fact that acceptance and functional tests have not been merged, we can exclude this method from the coverage report by using <code class="literal">@codeCoverageIgnore</code>. However, make sure that this isn't a case anymore and discuss it with your colleagues before excluding the method coverage from all the tests.</p><p>The last part that we need to cover is the controller of the REST interface. Here, we have a mixed situation. We have uncovered the functions that are mostly a part of our framework, such as the anonymous function that performs the authentication and <code class="literal">checkAccess()</code>, we have a small bit in <code class="literal">actionUpdate()</code>, which forbids anything but a PUT, and we have another control statement in <code class="literal">actionSearch()</code>, which controls who can search what.</p><p>In the first two cases we'll gladly avoid them from getting covered, as we've explicitly excluded the framework files which these two are part of.</p><p>For <code class="literal">actionUpdate(),</code> we'll find out that we won't even need a specific check, as Yii already defines the type of HTTP call that is allowed against the default REST interfaces.</p><p>We can add a <a id="id424" class="indexterm"/>test that ensures that we can't perform a POST on the interface and it can be added to any of the already present tests. This could be something along the lines of the following code block:</p><div class="informalexample"><pre class="programlisting">// tests/codeception/functional/UserAPIEndpointsCept.php

// I must be authenticated at this point.
$I-&gt;amGoingTo('I cannot update using POST');
$I-&gt;sendPOST('users/' . $userId);
$I-&gt;seeResponseCodeIs(405);</pre></div><p>Lastly, we want to ensure that the user can only search for his own username to get the ID, as we outlined in <a class="link" href="ch06.html" title="Chapter 6. Testing the API – PHPBrowser to the Rescue">Chapter 6</a>, <span class="emphasis"><em>Testing the API – PHPBrowser to the Rescue</em></span>. In order to do this, we can simply add something similar to the code block shown here:</p><div class="informalexample"><pre class="programlisting">// tests/codeception/functional/UserAPICept.php

// I must be authenticated at this point.
$I-&gt;amGoingTo('ensure I cannot search someone else');
$I-&gt;sendGET('users/search/someoneelse');
$I-&gt;seeResponseCodeIs(403);</pre></div><p>If we run the tests with coverage, then we'll get a 100 percent on all the files that we wanted to see the coverage on.</p><div class="mediaobject"><img src="graphics/B03646_08_07.jpg" alt="Aggregating functional tests to unit tests"/><div class="caption"><p>The final overview of the coverage for unit and functional tests</p></div></div></div><div class="section" title="Generating acceptance tests' coverage report"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec66"/>Generating acceptance tests' coverage report</h2></div></div></div><p>Now that <a id="id425" class="indexterm"/>we've seen what to make of our coverage reports, we'll quickly look at the configuration that will help us in obtaining the coverage reports for the acceptance tests.</p><p>These coverage reports might not be the most important ones, but if constructed correctly, then they should prove that our scenarios are well written. Normally, the focus of acceptance tests is on ensuring browser cross- and preserving retro-compatibility.</p><p>As we've seen in <a class="link" href="ch07.html" title="Chapter 7. Having Fun Doing Browser Testing">Chapter 7</a>, <span class="emphasis"><em>Having Fun Doing Browser Testing</em></span>, Codeception talks to the Selenium standalone server, which in turn launches the browser and performs the required tests through the browser driver. Because of this architecture, the c3 project has been created, which basically listens to the browser calls and understands which bit of our code is being executed remotely.</p><p>So, first of all, let's get c3. We can either download it from Composer or from the official website (<a class="ulink" href="https://github.com/Codeception/c3">https://github.com/Codeception/c3</a>) by running this command from the root of the project:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ wget https://raw.github.com/Codeception/c3/2.0/c3.php</strong></span>
</pre></div><p>If you're downloading it through Composer, then you'll have to add some additional instructions to the <code class="literal">composer.json</code> file. You should take the official documentation as the main reference point.</p><p>Once you have it, include it in the <code class="literal">index-test.php</code> file:</p><div class="informalexample"><pre class="programlisting">// web/index-test.php
//...
<span class="strong"><strong>include_once __DIR__ . '/c3.php';</strong></span>
$config = require(__DIR__ . '/../tests/codeception/config/acceptance.php');
(new yii\web\Application($config))-&gt;run();</pre></div><p>With this, we have hooked c3 to Yii. Now, we just need to make Codeception aware of it. So open the <code class="literal">codeception.yml</code> file, and add the following options to the <code class="literal">coverage</code> section of the file:</p><div class="informalexample"><pre class="programlisting"># tests/codeception.yml
# ...
coverage:
    enabled: true
    <span class="strong"><strong>remote: true</strong></span>
    <span class="strong"><strong>remote_config: ../tests/codeception.yml</strong></span>
    # whitelist:
    # blacklist:
    <span class="strong"><strong>c3_url: 'https://basic-dev.yii2.sandbox/index-test.php/'</strong></span>
</pre></div><p>We need to enable the remote coverage, set the configuration of the file by using <code class="literal">remote_config,</code> and then specify the URL c3 should be listening on.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note32"/>Note</h3><p>The detailed explanation of the remote code coverage and its configuration can be read from the official documentation of Codeception, which can be found at <a class="ulink" href="http://codeception.com/docs/11-Codecoverage">http://codeception.com/docs/11-Codecoverage</a>, and from the <code class="literal">README.md</code> file, which is either located in the <code class="literal">tests/</code> directory of your project or at <a class="ulink" href="https://github.com/yiisoft/yii2-app-basic/tree/master/tests#remote-code-coverage">https://github.com/yiisoft/yii2-app-basic/tree/master/tests#remote-code-coverage</a>.</p></div></div><p>Now, all <a id="id426" class="indexterm"/>our remote calls will go through the <code class="literal">index-test.php</code> file, and they will use c3 to generate the coverage data.</p><p>Additionally, we may want to get a trimmed down report for specific acceptance tests, and in our case, we can decide to focus our attention only on the controllers that are being hit, and then choose to remove any reporting for the models.</p><p>In order to do so, consider what we already have in the main configuration file. We just need to add the following to our <code class="literal">acceptance.suite.yml</code> file:</p><div class="informalexample"><pre class="programlisting"># tests/codeception/acceptance.suite.yml
coverage:
    blacklist:
        include:
            - ../models/*</pre></div><p>At this point, you can generate the reports separately by using the code block shown here:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ ../vendor/bin/codecept run acceptance --coverage-html</strong></span>
</pre></div><p>You can also do this by simply running the tests for the whole suite, as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ ../vendor/bin/codecept run --coverage-html</strong></span>
</pre></div><p>As we saw earlier, both of these methods will generate a separate report for the acceptance tests. It might happen that in the future this is no longer valid, so be sure to head over to the official documentation and check that.</p><p>Once we generate the reports, we will notice two things: the tests with the coverage report might take ages, so we don't want to run this every time we make a change to the interface. Secondly, we will have to cover the missing logout test that we have highlighted before.</p><p>So, let's go <a id="id427" class="indexterm"/>to our <code class="literal">LoginCept.php</code> file and add what's missing.</p><div class="informalexample"><pre class="programlisting">$I-&gt;amGoingTo('ensure I cannot load the login page if I am logged in');
$I-&gt;amOnPage('/index-test.php/login');
$I-&gt;seeCurrentUrlEquals('/index-test.php');

$I-&gt;amGoingTo('try to logout');
$I-&gt;click('Logout (admin)');
if (method_exists($I, 'wait')) {
    $I-&gt;wait(3); // only for selenium
}
$I-&gt;seeCurrentUrlEquals('/index-test.php');</pre></div><p>Please note that we need to be very specific while using the URLs, just as we were with the functional tests.</p><p>Once this is done, we should find ourselves with the complete coverage of all the suites.</p><p>In the next section, we'll see what else we can generate, and then we'll take it to the next level with the aid of automation in the next chapter.</p></div></div></div>
<div class="section" title="Improving our code with the aid of additional tools"><div class="titlepage"><div><div><h1 class="title"><a id="ch08lvl1sec44"/>Improving our code with the aid of additional tools</h1></div></div></div><p>In<a id="id428" class="indexterm"/> addition to code coverage and test reports, we have a range of additional tools, which we can use for improving the quality of our code.</p><p>The two tools that we're going to talk about are the check style and the cyclomatic complexity through the C.R.A.P. index.</p><p>We are going to add more examples and tools to these in <a class="link" href="ch09.html" title="Chapter 9. Eliminating Stress with the Help of Automation">Chapter 9</a>, <span class="emphasis"><em>Eliminating Stress with the Help of Automation</em></span>, as each command would require too much knowledge from the developer's side, and it is something that can be automated and triggered by the flick of a switch.</p><p>
<span class="strong"><strong>PHP Checkstyle</strong></span> (<span class="strong"><strong>PHPCS</strong></span>) is<a id="id429" class="indexterm"/> a great tool, albeit it is rather complex at first . This will help us in maintaining a style of code that is uniform for all developers. You might care too much about this, and I've seen situations where decisions on which style to use have resulted in a big fight. However, the benefits of this are quite evident, as it forces the developers to control their style of coding. When used with the cyclomatic complexity, it can standardize the code and avoid any situation involving intricate and difficult code.</p><p>There are<a id="id430" class="indexterm"/> some already existing code standards available for your use and these have been configured according to your needs. PHPCS only needs a reference for the configuration file or the name of the standard to follow.</p><p>We are going to install and use Yii 2 own code standards, which you can use as a base for specifying the rules that are more suited to your needs.</p><p>You can install the Yii 2 code standards by using Composer, which will include the actual binary that we need as a dependency:</p><div class="informalexample"><pre class="programlisting">// composer.json
    "require-dev": {
       ...
        <span class="strong"><strong>"yiisoft/yii2-coding-standards": "*"</strong></span>
</pre></div><p>Once we have installed both of them, we can invoke them through the console by using the following command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ vendor/bin/phpcs \--standard=vendor/yiisoft/yii2-coding-standards/Yii2/ruleset.xml \ --extensions=php \--ignore=autoload.php \models controllers modules</strong></span>
</pre></div><p>The last three arguments are the folders that we want PHPCS to scan.</p><p>If you want to improve your code, then you should make use of the C.R.A.P. index, which is included in the coverage reports generated by Codeception.  In the following chapter, we'll see how  the cyclomatic complexity index can be used for basing the decisions for modifying your code.</p><p>The C.R.A.P. index has been designed for analyzing and predicting the amount of effort, pain, and time required for maintaining an existing body of code.</p><p>It is mathematically defined as shown here:</p><p>
<span class="emphasis"><em>C.R.A.P.(m) = comp(m)^2 * (1 – cov(m)/100)^3 + comp(m)</em></span>
</p><p>Where <span class="emphasis"><em>comp(m)</em></span> is the cyclomatic complexity, and <span class="emphasis"><em>cov(m)</em></span> is the test code coverage provided by the automated tests. The cyclomatic complexity is calculated as 1 plus the number of unique decisions in the method.</p><p>A low C.R.A.P. index<a id="id431" class="indexterm"/> indicates a relatively low change and maintenance risk, because it's either not too complex or sufficiently covered by tests. To keep it practical, if your method is a straight sequence of calls, then it is likely that it will have a C.R.A.P. index that is close to 1. The more <code class="literal">if</code>, <code class="literal">for,</code> and <code class="literal">while</code> clauses it has, the more complex it will be, and hence it will have a higher C.R.A.P. index.</p><p>This is where testing lets the potential problems emerge and points you in the direction that you should be taking for keeping your code maintainable and modular.</p></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch08lvl1sec45"/>Summary</h1></div></div></div><p>In this chapter, we've discussed the basic steps needed for configuring and generating the code coverage for the project. We've seen how to use the reports generated for discovering potential problems with the code. We've also covered some additional tools for improving our code quality.</p><p>In <a class="link" href="ch09.html" title="Chapter 9. Eliminating Stress with the Help of Automation">Chapter 9</a>, <span class="emphasis"><em>Eliminating Stress with the Help of Automation</em></span>, we'll complete this journey. We will discuss the topic of additional tools, how to integrate them into a continuous integration system, and then display the results for better access and browsing.</p></div></body></html>